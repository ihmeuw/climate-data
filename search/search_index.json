{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Climate Database","text":"<p>The Climate Database contains a variety of data extracted from different sources. This page provides an overview of the data layout, the sources we've extracted data from, the data harmonization and downscaling process, and an overview of the available climate variables.</p>"},{"location":"#data-organization","title":"Data Organization","text":"<p>The root of the climate data is located at <code>/mnt/share/erf/climate_downscale</code>. There are several subdirectories in the root directory, but only the extracted data directory <code>extracted_data</code> and the results directory <code>results</code> are relevant to users of the database.</p> <p>The file tree with subdirectories is as follows:</p> <pre><code>/mnt/share/erf/climate_downscale/\n\u251c\u2500\u2500 extracted_data/\n\u2502   \u251c\u2500\u2500 era5/\n\u2502   \u2502   \u2514\u2500\u2500 {ERA5_DATASET}_{ERA5_VARIABLE}_{YEAR}_{MONTH}.nc\n\u2502   \u251c\u2500\u2500 cmip6/\n\u2502   \u2502   \u2514\u2500\u2500 {CMIP6_VARIABLE}_{CMIP6_EXPERIMENT}_{CMIP6_SOURCE}_{VARIANT}.nc\n\u2502   \u2514\u2500\u2500 _Other Data Sources_/\n\u2514\u2500\u2500 results/\n    \u251c\u2500\u2500 annual/\n    \u2502   \u251c\u2500\u2500 archive/\n    \u2502   \u2502   \u251c\u2500\u2500 historical/\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 {ANNUAL_VARIABLE}/\n    \u2502   \u2502   \u2502       \u2514\u2500\u2500 {YEAR}.nc\n    \u2502   \u2502   \u2514\u2500\u2500 {SCENARIO}/\n    \u2502   \u2502       \u2514\u2500\u2500 {ANNUAL_VARIABLE}/\n    \u2502   \u2502           \u2514\u2500\u2500 {YEAR}.nc\n    |   \u251c\u2500\u2500 raw/\n    \u2502   \u2502   \u251c\u2500\u2500 compiled/\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 {SCENARIO}/\n    \u2502   \u2502   \u2502       \u2514\u2500\u2500 {ANNUAL_VARIABLE}/\n    \u2502   \u2502   \u2502           \u2514\u2500\u2500 {GCM_MEMBER}.nc\n    \u2502   \u2502   \u251c\u2500\u2500 historical/\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 {ANNUAL_VARIABLE}/\n    \u2502   \u2502   \u2502       \u2514\u2500\u2500 {YEAR}_era5.nc\n    \u2502   \u2502   \u2514\u2500\u2500 {SCENARIO}/\n    \u2502   \u2502       \u2514\u2500\u2500 {ANNUAL_VARIABLE}/\n    \u2502   \u2502           \u2514\u2500\u2500 {YEAR}_{GCM_MEMBER}.nc\n    \u2502   \u2514\u2500\u2500 {SCENARIO}/\n    \u2502       \u2514\u2500\u2500 {ANNUAL_VARIABLE}/\n    \u2502           \u2514\u2500\u2500 {DRAW}.nc\n    \u251c\u2500\u2500 daily/\n    \u2502   \u2514\u2500\u2500 {SCENARIO}/\n    \u2502       \u2514\u2500\u2500 {DAILY_VARIABLE}/\n    \u2502           \u251c\u2500\u2500 {YEAR}.nc\n    \u2502           \u2514\u2500\u2500 reference.nc\n    \u2514\u2500\u2500 metadata/\n</code></pre> <p>The file patterns will be explained in more detail in the following sections.</p>"},{"location":"#extracted-data","title":"Extracted Data","text":"<p>The two primary data sources are historical climate data from the European Centre for Medium-Range Weather Forecasts (ECMWF) ERA5 dataset and climate forecast data from the Climate Model Intercomparison Project Phase 6 (CMIP6). There are also some additional data sources that have been extracted to serve as covariates in a forthcoming downscaling model.</p>"},{"location":"#era5-data","title":"ERA5 Data","text":"<p>The ECMWF Reanalysis v5 (ERA5) is the fifth generation ECMWF atmospheric reanalysis of the global climate covering the period from January 1950 to present. ERA5 is produced by the Copernicus Climate Change Service (C3S) at ECMWF. There are three datasets of note:</p> <ul> <li>The Complete ERA5 global atmospheric reanalysis:     This dataset contains a wide range of atmospheric, land, and oceanic climate variables on a regular latitude/longitude grid at a roughly 31km     resolution. Additionally it splits the atmosphere into 137 pressure levels starting at the Earth's surface and extending to a height of 80km.     We do not typically extract from this source as we generally have no need of the oceanic data or the data above the Earth's surface.</li> <li>ERA5-Land hourly data from 1950 to present:     This dataset contains land surface variables at the native model resolution of 9km. Variables not defined over the land surface (such as     sea surface temperature) are not present in this dataset. Additionally, this dataset sometimes misses some land area, especially islands and     regions. Because of its detailed resolution, this is the model we prefer to extract from wherever possible.</li> <li>ERA5 hourly data on single levels from 1940 to present:     This dataset contains a wide range of atmospheric, land, and oceanic climate variables on a regular latitude/longitude grid at a roughly 31km.     This dataset is similar to the complete ERA5 dataset, but it only contains data at the Earth's surface and at a few fixed pressure levels, making     it significantly smaller and faster to work with. This is the dataset we use to supplement the ERA5-Land data over regions where the land data is     missing or incomplete. We also use this dataset for variables that are not available in the ERA5-Land dataset.</li> </ul> <p>Storage and naming conventions</p> <p>File Pattern: <code>/mnt/share/erf/climate_downscale/extracted_data/era5/{ERA5_DATASET}_{ERA5_VARIABLE}_{YEAR}_{MONTH}.nc</code></p> <p>Naming Conventions</p> <ul> <li><code>{ERA5_DATASET}</code>: One of <code>reanalysis-era5-land</code>, or <code>reanalysis-era5-single-levels</code>.</li> <li><code>{ERA5_VARIABLE}</code>: The variable being extracted (one of <code>10m_u_component_of_wind</code>, <code>10m_v_component_of_wind</code>, <code>2m_dewpoint_temperature</code>, <code>2m_temperature</code>, <code>surface_pressure</code>, <code>total_precipitation</code>, <code>sea_surface_temperature</code>).</li> <li><code>{YEAR}</code> and <code>{MONTH}</code>: The year and month of the data being extracted. <code>{YEAR}</code> ranges from <code>1950</code> to <code>2023</code>.</li> </ul>"},{"location":"#cmip6-data","title":"CMIP6 Data","text":"<p>The Climate Model Intercomparison Project Phase 6 (CMIP6) is a collaborative effort to compare climate models across the globe. The data is organized into different variables, scenarios, and sources.</p> <p>Storage and Naming Conventions</p> <p>File Pattern: <code>/mnt/share/erf/climate_downscale/extracted_data/cmip6/{CMIP6_VARIABLE}_{CMIP6_EXPERIMENT}_{CMIP6_SOURCE}_{VARIANT}.nc</code></p> <p>Naming Conventions</p> <ul> <li><code>{CMIP6_VARIABLE}</code>: The variable being extracted (one of <code>uas</code>, <code>vas</code>, <code>hurs</code>, <code>tas</code>, <code>tasmin</code>, <code>tasmax</code>, <code>tos</code>, <code>pr</code>).</li> <li><code>{CMIP6_EXPERIMENT}</code>: The scenario being extracted (one of <code>ssp126</code>, <code>ssp245</code>, <code>ssp585</code>).</li> <li><code>{CMIP6_SOURCE}</code>: The source model for the data. A source model is a particular model from a particular institution, e.g. <code>BCC-CSM2-MR</code>.</li> <li><code>{VARIANT}</code>: The variant of the model, which is a particular run of the model with specific initial and boundary conditions and forcing scenarios.</li> </ul>"},{"location":"#model-inclusion","title":"Model Inclusion","text":"<p>We use a subset of the CMIP6 data in our analysis following a model evaluation published in Nature that determined which models to include based on their performance. Our inclusion criteria are as follows:</p> <ol> <li>The model must be flagged as \"Yes\" in the <code>Included in 'Model Subset'?</code> column in the evaluation table.</li> <li>The model must have daily results (which concretely means there is either a <code>day</code> or <code>Oday</code> table_id associated with the model).</li> <li>The model must make estimates for the three scenarios we are interested in: <code>ssp126</code>, <code>ssp245</code>, and <code>ssp585</code>.</li> <li>The model must cover the time range 2019-2099. We project out to 2100, and many models run a 2100 year, but some stop at 2099. They are incorporated here with their last year repeated.</li> </ol> <p>Model Inclusion Caveats</p> <p>The extraction criteria does not completely capture model inclusion criteria as it does not account for the year range available in the data. This determination is made when we process the data in later steps. See the scenario inclusion stage of the processing pipeline for more detail.</p>"},{"location":"#data-availability","title":"Data Availability","text":"<p>The following tables show the number of unique models available for each variable.</p> Model CountSource Breakdown variable Source Count Variant Count hurs 15 34 pr 18 35 tas 20 44 tasmax 18 39 tasmin 17 37 tos 9 22 uas 16 35 vas 17 35 source hurs pr tas tasmax tasmin tos uas vas ACCESS-CM2 3 2 2 3 2 2 1 1 AWI-CM-1-1-MR 1 1 1 1 1 1 1 1 BCC-CSM2-MR 0 1 1 1 1 1 1 1 CAMS-CSM1-0 0 1 1 1 0 0 0 0 CMCC-CM2-SR5 1 1 1 1 1 1 0 1 CMCC-ESM2 1 1 1 1 1 0 1 1 CNRM-CM6-1 6 1 6 1 1 0 6 6 CNRM-CM6-1-HR 1 0 0 0 0 0 1 1 CNRM-ESM2-1 3 1 4 1 1 0 3 3 FGOALS-g3 0 0 4 4 4 0 0 0 GFDL-ESM4 1 1 1 1 1 0 1 1 GISS-E2-1-G 0 0 1 0 0 0 0 0 IITM-ESM 1 1 1 0 0 0 1 1 INM-CM4-8 1 1 1 1 1 0 1 1 INM-CM5-0 1 1 1 1 1 0 1 1 MIROC-ES2L 0 1 1 1 1 0 1 1 MIROC6 0 3 3 3 3 3 3 3 MPI-ESM1-2-HR 2 2 2 2 2 2 2 1 MPI-ESM1-2-LR 10 10 10 10 10 10 10 10 MRI-ESM2-0 1 5 1 5 5 1 1 1 NorESM2-MM 1 1 1 1 1 1 0 0 Variant Labels <p>For a given experiment, the realization_index, initialization_index, physics_index, and forcing_index are used to uniquely identify each simulation of an ensemble of runs contributed by a single model. These indices are defined as follows:</p> <ul> <li>realization_index = an integer (\u22651) distinguishing among members of an ensemble of simulations that differ only in their initial conditions (e.g.,     initialized from different points in a control run). Note that if two different simulations were started from the same initial conditions, the     same realization number should be used for both simulations. For example if a historical run with \u201cnatural forcing\u201d only and another historical     run that includes anthropogenic forcing were both spawned at the same point in a control run, both should be assigned the same realization. Also,     each so-called RCP (future scenario) simulation should normally be assigned the same realization integer as the historical run from which it was     initiated. This will allow users to easily splice together the appropriate historical and future runs.</li> <li>initialization_index = an integer (\u22651), which should be assigned a value of 1 except to distinguish simulations performed under the same conditions     but with different initialization procedures. In CMIP6 this index should invariably be assigned the value \u201c1\u201d except for some hindcast and forecast     experiments called for by the DCPP activity. The initialization_index can be used either to distinguish between different algorithms used to impose     initial conditions on a forecast or to distinguish between different observational datasets used to initialize a forecast.</li> <li>physics_index = an integer (\u22651) identifying the physics version used by the model. In the usual case of a single physics version of a model, this     argument should normally be assigned the value 1, but it is essential that a consistent assignment of physics_index be used across all simulations     performed by a particular model. Use of \u201cphysics_index\u201d is reserved for closely-related model versions (e.g., as in a \u201cperturbed physics\u201d ensemble)     or for the same model run with slightly different parameterizations (e.g., of cloud physics). Model versions that are substantially different from     one another should be given a different source_id\u201d (rather than simply assigning a different value of the physics_index).</li> <li>forcing_index = an integer (\u22651) used to distinguish runs conforming to the protocol of a single CMIP6 experiment, but with different variants of     forcing applied. One can, for example, distinguish between two historical simulations, one forced with the CMIP6-recommended forcing data sets     and another forced by a different dataset, which might yield information about how forcing uncertainty affects the simulation.</li> </ul>"},{"location":"#processed-data","title":"Processed Data","text":"<p>The processed data is stored in the <code>/mnt/share/erf/climate_downscale/results</code> directory, organized by scenario and variable.</p> <p>There are two types of processed data: daily and annual. Daily data is stored for historical data only (and for the <code>mean_temperature</code> variable for CMIP6 data). We generally only generate annual results, as storing daily results for all models and all variables would be prohibitively expensive. Daily data is stored in the <code>/mnt/share/erf/climate_downscale/results/daily</code> directory.</p> <p>Daily Data Storage and Naming Conventions</p> <p>File Patterns:</p> <ul> <li><code>/mnt/share/erf/climate_downscale/results/daily/historical/{DAILY_VARIABLE}/{YEAR}.nc</code> - Daily data for historical variables.</li> <li><code>/mnt/share/erf/climate_downscale/results/daily/historical/{DAILY_VARIABLE}/reference.nc</code> - Reference climatology data for historical variables.</li> <li><code>/mnt/share/erf/climate_downscale/results/daily/{SCENARIO}/mean_temperature/{YEAR}.nc</code> - Daily data for the <code>mean_temperature</code> variable for CMIP6 scenarios.</li> </ul> <p>Naming Conventions</p> <ul> <li><code>{SCENARIO}</code>: The CMIP6 scenario being stored (one of <code>ssp126</code>, <code>ssp245</code>, <code>ssp585</code>).</li> <li><code>{DAILY_VARIABLE}</code>: The name of the variable being stored (one of <code>mean_temperature</code>, <code>max_temperature</code>, <code>min_temperature</code>, <code>wind_speed</code>, <code>relative_humidity</code>, <code>total_precipitation</code>).</li> <li><code>{YEAR}</code>: The year of the data being stored. In <code>historical</code> subdirectories, this runs from <code>1950</code> to <code>2023</code>.   In scenario subdirectories, this runs from <code>2024</code> to <code>2100</code>.</li> </ul> <p>The annual data is stored in the <code>/mnt/share/erf/climate_downscale/results/annual</code> directory. Annual data is stored by draw number, with each draw representing a random sample of a Global Climate Model (GCM) and variant from CMIP6. Each draw is a full annual time series from 1950 to 2100 and collates the historical ERA5 data with the CMIP6 scenario data.</p> <p>Annual Data Storage and Naming Conventions</p> <p>Archive File Patterns</p> <p>These store the prior results for the climate database to ease transition to the new draw-level outputs. They use an older version of the CMIP6 ensemble and represent an ensemble mean.  They should be transitioned to the new draw-level outputs as soon as possible.</p> <ul> <li><code>/mnt/share/erf/climate_downscale/results/annual/archive/historical/{ANNUAL_VARIABLE}/{YEAR}.nc</code> - Archived historical annual data using the ERA5 dataset.</li> <li><code>/mnt/share/erf/climate_downscale/results/annual/archive/{SCENARIO}/{ANNUAL_VARIABLE}/{YEAR}.nc</code> - Archived scenario annual data using the CMIP6 dataset and the original point estimate ensemble.</li> </ul> <p>Raw and Compiled File Patterns</p> <ul> <li><code>/mnt/share/erf/climate_downscale/results/annual/raw/historical/{ANNUAL_VARIABLE}/{YEAR}_era5.nc</code> - Raw historical annual data using the ERA5 dataset.</li> <li><code>/mnt/share/erf/climate_downscale/results/annual/raw/{SCENARIO}/{ANNUAL_VARIABLE}/{YEAR}_{GCM_MEMBER}.nc</code> - Raw scenario annual data using the CMIP6 dataset. Each dataset is a bias-corrected and downscaled GCM-member.</li> <li><code>/mnt/share/erf/climate_downscale/results/annual/raw/compiled/{SCENARIO}/{ANNUAL_VARIABLE}/{GCM_MEMBER}.nc</code> - Annual compilations of the raw scenario data for each GCM-member.</li> </ul> <p>Draw File Pattern: /mnt/share/erf/climate_downscale/results/{SCENARIO}/{ANNUAL_VARIABLE}/{DRAW}.nc</p> <p>Naming Conventions</p> <ul> <li><code>{ANNUAL_VARIABLE}</code>: The name of the variable being stored (one of <code>mean_temperature</code>, <code>mean_high_temperature</code>, <code>mean_low_temperature</code>, <code>days_over_30C</code>, <code>malaria_suitability</code>, <code>dengue_suitability</code>, <code>wind_speed</code>, <code>relative_humidity</code>, <code>total_precipitation</code>, <code>precipitation_days</code>).</li> <li><code>{SCENARIO}</code>: The scenario being stored (one of <code>ssp126</code>, <code>ssp245</code>, <code>ssp585</code>).</li> <li><code>{YEAR}</code>: The year of the data being stored. In <code>historical</code> subdirectories, this runs from <code>1950</code> to <code>2023</code>.   In scenario subdirectories, this runs from <code>2024</code> to <code>2100</code>.</li> <li><code>{GCM_MEMBER}</code>: The GCM member being stored. This is a unique identifier for each GCM member combining the source model and variant.</li> <li><code>{DRAW}</code>: The draw number of the data being stored as a three digit string (e.g. <code>027</code>).</li> </ul>"},{"location":"#pipeline-stages","title":"Pipeline Stages","text":"<p>The processing pipelines turn the extracted ERA5 and CMIP6 data into a coherent set of climate variables with a consistent resolution, time scale, and data storage format. The pipeline is run with the <code>cdrun</code> command (see Installation for installation instructions). The pipeline has the following steps:</p> <ol> <li>Historical Daily (<code>cdrun generate historical_daily</code>): This processes the hourly ERA5-Land and ERA5-Single-Level       data into a unified daily format, pulling the higher-resolution ERA5-Land data where available and filling in       with ERA5-Single-Level data. Historical daily data is produced for all core variables (those not derived by       computing annual summary statistics from the daily data).</li> <li>Historical Reference (<code>cdrun generate historical_reference</code>): This produces a set of reference climatologies       from the historical daily data. These reference climatologies are built by averaging the last 5 years of       historical data grouped by month. For example, the reference climatology for January mean temperature is the       average of all Januare mean daily temperatures from 2019 to 2023. These climatologies are used to bias-correct       the scenario data by serving as a seasonally-aware reference point we can intercept shift to.</li> <li>Scenario Inclusion (<code>cdrun generate scenario_inclusion</code>): This produces a set of metadata that determines       which CMIP sources and variants are used to generate scenario draws. This is the second stage scenario determination.       When we extract CMIP6 data, we cannot determine the year range of the data until it is extracted.       This stage determines which models are included based on the year range of the data and writes this information to a file       in /mnt/share/erf/climate_downscale/results/metadata.</li> <li>Scenario Daily (<code>cdrun generate scenario_daily</code>): This produces scenario projections from the CMIP6 data by dynamical       downscaling the daily data to the same resolution as the ERA5 data. Our downscaling process computes the absolute or       relative anomaly of a forecast day from a CMIP6 model relative to what that model's average prediction in the month       over the reference period (2019-2023). This anomaly is then downscaled using linear interpolation to the ERA5 grid.       The downscaled anomaly is then applied back to the reference climatology, which adds in fine-scale detail and provides       a seasonally-aware bias correction. This produces draw level estimates using a two-stage sampling method, first selecting       a CMIP <code>source</code> model, and then selecting a <code>variant</code> from that model.  This sampling method ensures each model of the ensemble       is equally represented despite the large difference in the number of variants produced by each source model.       NOTE: This stage is not typically invoked on its own, as storing draw-level daily data for all models and all       variables is prohibitively expensive. It is instead invoked indirectly as part of the scenario annual stage.</li> <li>Scenario Annual (<code>cdrun generate scenario_annual</code>): This produces annual estimates of the climate variables.       It invokes the scenario daily stage to produce daily data, then computes annual summaries of the daily data, saving       only the annual summary.</li> </ol>"},{"location":"#_1","title":"Home","text":""},{"location":"installation/","title":"Climate Data Pipeline Installation","text":"<p>This package contains pipelines and utilities to systematically extract, format, and downscale data from ERA5 climate models and CMIP6 climate forecasts.</p>"},{"location":"installation/#developer-installation","title":"Developer Installation","text":"<p>Instructions using <code>conda</code>:</p> <ol> <li> <p>Clone this repository.</p> <p>Over ssh: <pre><code>git clone git@github.com:ihmeuw/climate-data.git\n</code></pre></p> <p>Over https: <pre><code>git clone https://github.com/ihmeuw/climate-data.git\n</code></pre></p> </li> <li> <p>Create a new conda environment.</p> <pre><code>conda create -n climate-data python=3.12\nconda activate climate-data\n</code></pre> </li> <li> <p>Install <code>poetry</code> and the project dependencies.</p> <pre><code>pip install poetry\ncd climate-data\npoetry install\n</code></pre> </li> </ol>"},{"location":"installation/#pre-commit","title":"Pre-commit","text":"<p><code>pre-commit</code> hooks run all the auto-formatting (<code>ruff format</code>), linters (e.g. <code>ruff</code> and <code>mypy</code>), and other quality checks to make sure the changeset is in good shape before a commit/push happens.</p> <p>You can install the hooks with (runs for each commit):</p> <pre><code>pre-commit install\n</code></pre> <p>Or if you want them to run only for each push:</p> <pre><code>pre-commit install -t pre-push\n</code></pre> <p>Or if you want e.g. want to run all checks manually for all files:</p> <pre><code>poetry run pre-commit run --all-files\n</code></pre> <p><code>pre-commit</code> is configured in the <code>.pre-commit-config.yaml</code> file in the repository root. All auto-formatting, linting, and other tooling is configured in the <code>pyproject.toml</code> file.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>climate_data<ul> <li>cli</li> <li>cli_options</li> <li>constants</li> <li>data</li> <li>downscale<ul> <li>prepare_predictors</li> <li>prepare_training_data</li> </ul> </li> <li>extract<ul> <li>cmip6</li> <li>elevation</li> <li>era5</li> <li>ncei_climate_stations</li> <li>rub_local_climate_zones</li> </ul> </li> <li>generate<ul> <li>draws</li> <li>historical_daily</li> <li>historical_reference</li> <li>scenario_annual</li> <li>scenario_daily</li> <li>scenario_inclusion</li> <li>temperature_zones</li> <li>utils</li> </ul> </li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/climate_data/","title":"climate_data","text":""},{"location":"reference/climate_data/#climate_data--climate-data","title":"Climate Data","text":"<p>This package contains modules for extracting, processing, harmonizing, and downscaling climate data. It sources historical climate data from the European Centre for Medium-Range Weather Forecasts (ECMWF) ERA5 dataset and future climate data from the Coupled Model Intercomparison Project Phase 6 (CMIP6).</p>"},{"location":"reference/climate_data/#climate_data.cli","title":"<code>cli</code>","text":""},{"location":"reference/climate_data/#climate_data.cli.cdrun","title":"<code>cdrun() -&gt; None</code>","text":"<p>Entry point for running climate downscale workflows.</p> Source code in <code>src/climate_data/cli.py</code> <pre><code>@click.group()\ndef cdrun() -&gt; None:\n    \"\"\"Entry point for running climate downscale workflows.\"\"\"\n</code></pre>"},{"location":"reference/climate_data/#climate_data.cli.cdtask","title":"<code>cdtask() -&gt; None</code>","text":"<p>Entry point for running climate downscale tasks.</p> Source code in <code>src/climate_data/cli.py</code> <pre><code>@click.group()\ndef cdtask() -&gt; None:\n    \"\"\"Entry point for running climate downscale tasks.\"\"\"\n</code></pre>"},{"location":"reference/climate_data/#climate_data.cli_options","title":"<code>cli_options</code>","text":""},{"location":"reference/climate_data/#climate_data.cli_options--climate-data-cli-options","title":"Climate Data CLI Options","text":"<p>This module provides a set of CLI options for extracting climate data from the ERA5 and CMIP6 datasets. These options are used to specify the data to extract, such as the year, month, variable, and dataset. It also provides global variables representing the full space of valid values for these options.</p>"},{"location":"reference/climate_data/#climate_data.cli_options.with_year","title":"<code>with_year(years: Collection[str], *, allow_all: bool = False) -&gt; Callable[[Callable[P, T]], Callable[P, T]]</code>","text":"<p>Create a CLI option for selecting a year.</p> Source code in <code>src/climate_data/cli_options.py</code> <pre><code>def with_year[**P, T](\n    years: Collection[str],\n    *,\n    allow_all: bool = False,\n) -&gt; Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Create a CLI option for selecting a year.\"\"\"\n    return with_choice(\n        \"year\",\n        \"y\",\n        allow_all=allow_all,\n        choices=years,\n        help=\"Year to extract data for.\",\n        convert=allow_all,\n    )\n</code></pre>"},{"location":"reference/climate_data/#climate_data.data","title":"<code>data</code>","text":""},{"location":"reference/climate_data/#climate_data.data--climate-data-management","title":"Climate Data Management","text":"<p>This module provides a class for managing the climate data used in the project. It includes methods for loading and saving data, as well as for accessing the various directories where data is stored. This abstraction allows for easy access to the data and ensures that all data is stored in a consistent and organized manner. It also provides a central location for managing the data, which makes it easier to update and maintain the path structure of the data as needed.</p> <p>This module generally does not load or process data itself, though some exceptions are made for metadata which is generally loaded and cached on disk.</p>"},{"location":"reference/climate_data/#climate_data.data.ClimateData","title":"<code>ClimateData</code>","text":"<p>Class for managing the climate data used in the project.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>class ClimateData:\n    \"\"\"Class for managing the climate data used in the project.\"\"\"\n\n    def __init__(\n        self, root: str | Path = cdc.MODEL_ROOT, *, create_root: bool = True\n    ) -&gt; None:\n        self._root = Path(root)\n        self._credentials_root = self._root / \"credentials\"\n        if create_root:\n            self._create_model_root()\n\n    def _create_model_root(self) -&gt; None:\n        mkdir(self.root, exist_ok=True)\n        mkdir(self.credentials_root, exist_ok=True)\n\n        mkdir(self.extracted_data, exist_ok=True)\n        mkdir(self.extracted_era5, exist_ok=True)\n        mkdir(self.extracted_cmip6, exist_ok=True)\n        mkdir(self.ncei_climate_stations, exist_ok=True)\n        mkdir(self.open_topography_elevation, exist_ok=True)\n        mkdir(self.rub_local_climate_zones, exist_ok=True)\n\n        mkdir(self.downscale_model, exist_ok=True)\n        mkdir(self.predictors, exist_ok=True)\n        mkdir(self.training_data, exist_ok=True)\n\n        mkdir(self.results, exist_ok=True)\n        mkdir(self.results_metadata, exist_ok=True)\n        mkdir(self.daily_results, exist_ok=True)\n        mkdir(self.raw_daily_results, exist_ok=True)\n        mkdir(self.annual_results, exist_ok=True)\n        mkdir(self.raw_annual_results, exist_ok=True)\n\n    @property\n    def root(self) -&gt; Path:\n        return self._root\n\n    @property\n    def credentials_root(self) -&gt; Path:\n        return self._credentials_root\n\n    ##################\n    # Extracted data #\n    ##################\n\n    @property\n    def extracted_data(self) -&gt; Path:\n        return self.root / \"extracted_data\"\n\n    @property\n    def extracted_era5(self) -&gt; Path:\n        return self.extracted_data / \"era5\"\n\n    def extracted_era5_path(\n        self, dataset: str, variable: str, year: int | str, month: str\n    ) -&gt; Path:\n        return self.extracted_era5 / f\"{dataset}_{variable}_{year}_{month}.nc\"\n\n    @property\n    def extracted_cmip6(self) -&gt; Path:\n        return self.extracted_data / \"cmip6\"\n\n    def load_koppen_geiger_model_inclusion(\n        self, *, return_full_criteria: bool = False\n    ) -&gt; pd.DataFrame:\n        meta_path = self.extracted_cmip6 / \"koppen_geiger_model_inclusion.parquet\"\n\n        if not meta_path.exists():\n            df = pd.read_html(\n                \"https://www.nature.com/articles/s41597-023-02549-6/tables/3\"\n            )[0]\n            df.columns = [  # type: ignore[assignment]\n                \"source_id\",\n                \"member_count\",\n                \"mean_trend\",\n                \"std_dev_trend\",\n                \"transient_climate_response\",\n                \"equilibrium_climate_sensitivity\",\n                \"included_raw\",\n            ]\n            df[\"included\"] = df[\"included_raw\"].apply({\"Yes\": True, \"No\": False}.get)\n            save_parquet(df, meta_path)\n\n        df = pd.read_parquet(meta_path)\n        if return_full_criteria:\n            return df\n        return df[[\"source_id\", \"included\"]]\n\n    def load_cmip6_metadata(self) -&gt; pd.DataFrame:\n        meta_path = self.extracted_cmip6 / \"cmip6-metadata.parquet\"\n\n        if not meta_path.exists():\n            external_path = \"https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv\"\n            meta = pd.read_csv(external_path)\n            save_parquet(meta, meta_path)\n\n        return pd.read_parquet(meta_path)\n\n    def extracted_cmip6_path(\n        self,\n        variable: str,\n        experiment: str,\n        gcm_member: str,\n    ) -&gt; Path:\n        return self.extracted_cmip6 / f\"{variable}_{experiment}_{gcm_member}.nc\"\n\n    def get_gcms(\n        self,\n        source_variables: Collection[str],\n    ) -&gt; list[str]:\n        inclusion_meta = self.load_scenario_inclusion_metadata()[source_variables]\n        inclusion_meta = inclusion_meta[inclusion_meta.all(axis=1)]\n        return [\n            f\"{model}_{variant}\" for model, variant in inclusion_meta.index.tolist()\n        ]\n\n    @property\n    def ncei_climate_stations(self) -&gt; Path:\n        return self.extracted_data / \"ncei_climate_stations\"\n\n    def save_ncei_climate_stations(self, df: pd.DataFrame, year: int | str) -&gt; None:\n        path = self.ncei_climate_stations / f\"{year}.parquet\"\n        save_parquet(df, path)\n\n    def load_ncei_climate_stations(self, year: int | str) -&gt; pd.DataFrame:\n        return pd.read_parquet(self.ncei_climate_stations / f\"{year}.parquet\")\n\n    @property\n    def open_topography_elevation(self) -&gt; Path:\n        return self.extracted_data / \"open_topography_elevation\"\n\n    @property\n    def rub_local_climate_zones(self) -&gt; Path:\n        return self.extracted_data / \"rub_local_climate_zones\"\n\n    ###################\n    # Downscale model #\n    ###################\n\n    @property\n    def downscale_model(self) -&gt; Path:\n        return self.root / \"downscale_model\"\n\n    @property\n    def predictors(self) -&gt; Path:\n        return self.downscale_model / \"predictors\"\n\n    def save_predictor(\n        self,\n        predictor: rt.RasterArray,\n        name: str,\n        lat_start: int,\n        lon_start: int,\n    ) -&gt; None:\n        path = self.predictors / f\"{name}_{lat_start}_{lon_start}.tif\"\n        save_raster(predictor, path)\n\n    def load_predictor(self, name: str) -&gt; rt.RasterArray:\n        paths = list(self.predictors.glob(f\"{name}_*.tif\"))\n        return rt.load_mf_raster(paths)\n\n    @property\n    def training_data(self) -&gt; Path:\n        return self.downscale_model / \"training_data\"\n\n    def save_training_data(self, df: pd.DataFrame, year: int | str) -&gt; None:\n        path = self.training_data / f\"{year}.parquet\"\n        save_parquet(df, path)\n\n    def load_training_data(self, year: int | str) -&gt; pd.DataFrame:\n        return pd.read_parquet(self.training_data / f\"{year}.parquet\")\n\n    ###########\n    # Results #\n    ###########\n\n    @property\n    def results(self) -&gt; Path:\n        return self.root / \"results\"\n\n    @property\n    def results_metadata(self) -&gt; Path:\n        return self.results / \"metadata\"\n\n    def save_scenario_metadata(self, df: pd.DataFrame) -&gt; None:\n        path = self.results_metadata / \"scenario_metadata.parquet\"\n        save_parquet(df, path)\n\n    def load_scenario_metadata(self) -&gt; pd.DataFrame:\n        path = self.results_metadata / \"scenario_metadata.parquet\"\n        return pd.read_parquet(path)\n\n    def save_scenario_inclusion_metadata(self, df: pd.DataFrame) -&gt; None:\n        # Need to save to our scripts directory for doc building\n        scripts_root = Path(__file__).parent.parent.parent / \"scripts\"\n        for root_dir in [self.results_metadata, scripts_root]:\n            path = root_dir / \"scenario_inclusion_metadata.parquet\"\n            save_parquet(df, path)\n\n    def load_scenario_inclusion_metadata(self) -&gt; pd.DataFrame:\n        path = self.results_metadata / \"scenario_inclusion_metadata.parquet\"\n        return pd.read_parquet(path)\n\n    @property\n    def daily_results(self) -&gt; Path:\n        return self.results / \"daily\"\n\n    @property\n    def raw_daily_results(self) -&gt; Path:\n        return self.daily_results / \"raw\"\n\n    def raw_daily_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        gcm_member: str,\n    ) -&gt; Path:\n        return self.raw_daily_results / scenario / variable / f\"{year}_{gcm_member}.nc\"\n\n    def save_raw_daily_results(\n        self,\n        results_ds: xr.Dataset,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        gcm_member: str,\n        encoding_kwargs: dict[str, Any],\n    ) -&gt; None:\n        path = self.raw_daily_results_path(scenario, variable, year, gcm_member)\n        mkdir(path.parent, exist_ok=True, parents=True)\n        save_xarray(results_ds, path, encoding_kwargs)\n\n    def daily_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        year: int | str,\n    ) -&gt; Path:\n        return self.daily_results / scenario / variable / f\"{year}.nc\"\n\n    def save_daily_results(\n        self,\n        results_ds: xr.Dataset,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        encoding_kwargs: dict[str, Any],\n    ) -&gt; None:\n        path = self.daily_results_path(scenario, variable, year)\n        mkdir(path.parent, exist_ok=True, parents=True)\n        save_xarray(results_ds, path, encoding_kwargs)\n\n    def load_daily_results(\n        self,\n        scenario: str,\n        variable: str,\n        year: int | str,\n    ) -&gt; xr.Dataset:\n        results_path = self.daily_results_path(scenario, variable, year)\n        return xr.open_dataset(results_path)\n\n    @property\n    def annual_results(self) -&gt; Path:\n        return self.results / \"annual\"\n\n    @property\n    def raw_annual_results(self) -&gt; Path:\n        return self.annual_results / \"raw\"\n\n    def raw_annual_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        gcm_member: str,\n    ) -&gt; Path:\n        return self.raw_annual_results / scenario / variable / f\"{year}_{gcm_member}.nc\"\n\n    def save_raw_annual_results(\n        self,\n        results_ds: xr.Dataset,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        gcm_member: str,\n        encoding_kwargs: dict[str, Any],\n    ) -&gt; None:\n        path = self.raw_annual_results_path(scenario, variable, year, gcm_member)\n        mkdir(path.parent, exist_ok=True, parents=True)\n        save_xarray(results_ds, path, encoding_kwargs)\n\n    @property\n    def compiled_annual_results(self) -&gt; Path:\n        return self.raw_annual_results / \"compiled\"\n\n    def compiled_annual_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        gcm_member: str,\n    ) -&gt; Path:\n        return self.compiled_annual_results / scenario / variable / f\"{gcm_member}.nc\"\n\n    def save_compiled_annual_results(\n        self,\n        results_ds: xr.Dataset,\n        scenario: str,\n        variable: str,\n        gcm_member: str,\n    ) -&gt; None:\n        path = self.compiled_annual_results_path(scenario, variable, gcm_member)\n        mkdir(path.parent, exist_ok=True, parents=True)\n        touch(path, clobber=True)\n        results_ds.to_netcdf(path)\n\n    def annual_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        draw: int | str,\n    ) -&gt; Path:\n        return self.annual_results / scenario / variable / f\"{draw:0&gt;3}.nc\"\n\n    def link_annual_draw(\n        self,\n        draw: int | str,\n        scenario: str,\n        variable: str,\n        gcm_member: str,\n    ) -&gt; None:\n        source_path = self.compiled_annual_results_path(scenario, variable, gcm_member)\n        dest_path = self.annual_results_path(scenario, variable, draw)\n        mkdir(dest_path.parent, exist_ok=True, parents=True)\n        if dest_path.exists():\n            dest_path.unlink()\n        dest_path.symlink_to(source_path)\n</code></pre>"},{"location":"reference/climate_data/#climate_data.data.save_parquet","title":"<code>save_parquet(df: pd.DataFrame, output_path: str | Path) -&gt; None</code>","text":"<p>Save a pandas DataFrame to a file with standard parameters.</p>"},{"location":"reference/climate_data/#climate_data.data.save_parquet--parameters","title":"Parameters","text":"<p>df     The DataFrame to save. output_path     The path to save the DataFrame to.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>def save_parquet(\n    df: pd.DataFrame,\n    output_path: str | Path,\n) -&gt; None:\n    \"\"\"Save a pandas DataFrame to a file with standard parameters.\n\n    Parameters\n    ----------\n    df\n        The DataFrame to save.\n    output_path\n        The path to save the DataFrame to.\n    \"\"\"\n    touch(output_path, clobber=True)\n    df.to_parquet(output_path)\n</code></pre>"},{"location":"reference/climate_data/#climate_data.data.save_raster","title":"<code>save_raster(raster: rt.RasterArray, output_path: str | Path, num_cores: int = 1, **kwargs: Any) -&gt; None</code>","text":"<p>Save a raster to a file with standard parameters.</p>"},{"location":"reference/climate_data/#climate_data.data.save_raster--parameters","title":"Parameters","text":"<p>raster     The raster to save. output_path     The path to save the raster to. num_cores     The number of cores to use for compression.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>def save_raster(\n    raster: rt.RasterArray,\n    output_path: str | Path,\n    num_cores: int = 1,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Save a raster to a file with standard parameters.\n\n    Parameters\n    ----------\n    raster\n        The raster to save.\n    output_path\n        The path to save the raster to.\n    num_cores\n        The number of cores to use for compression.\n    \"\"\"\n    save_params = {\n        \"tiled\": True,\n        \"blockxsize\": 512,\n        \"blockysize\": 512,\n        \"compress\": \"ZSTD\",\n        \"predictor\": 2,  # horizontal differencing\n        \"num_threads\": num_cores,\n        \"bigtiff\": \"yes\",\n        **kwargs,\n    }\n    touch(output_path, clobber=True)\n    raster.to_file(output_path, **save_params)\n</code></pre>"},{"location":"reference/climate_data/#climate_data.data.save_raster_to_cog","title":"<code>save_raster_to_cog(raster: rt.RasterArray, output_path: str | Path, num_cores: int = 1, resampling: str = 'nearest') -&gt; None</code>","text":"<p>Save a raster to a COG file.</p> <p>A COG file is a cloud-optimized GeoTIFF that is optimized for use in cloud storage systems. This function saves the raster to a COG file with the specified resampling method.</p>"},{"location":"reference/climate_data/#climate_data.data.save_raster_to_cog--parameters","title":"Parameters","text":"<p>raster     The raster to save. output_path     The path to save the raster to. num_cores     The number of cores to use for compression. resampling     The resampling method to use when building the overviews.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>def save_raster_to_cog(\n    raster: rt.RasterArray,\n    output_path: str | Path,\n    num_cores: int = 1,\n    resampling: str = \"nearest\",\n) -&gt; None:\n    \"\"\"Save a raster to a COG file.\n\n    A COG file is a cloud-optimized GeoTIFF that is optimized for use in cloud storage\n    systems. This function saves the raster to a COG file with the specified resampling\n    method.\n\n    Parameters\n    ----------\n    raster\n        The raster to save.\n    output_path\n        The path to save the raster to.\n    num_cores\n        The number of cores to use for compression.\n    resampling\n        The resampling method to use when building the overviews.\n    \"\"\"\n    cog_save_params = {\n        \"driver\": \"COG\",\n        \"overview_resampling\": resampling,\n    }\n    save_raster(raster, output_path, num_cores, **cog_save_params)\n</code></pre>"},{"location":"reference/climate_data/#climate_data.data.save_xarray","title":"<code>save_xarray(ds: xr.Dataset, output_path: str | Path, encoding_kwargs: dict[str, Any]) -&gt; None</code>","text":"<p>Save an xarray dataset to a file with standard parameters.</p>"},{"location":"reference/climate_data/#climate_data.data.save_xarray--parameters","title":"Parameters","text":"<p>ds     The dataset to save. output_path     The path to save the dataset to. encoding_kwargs     The encoding parameters to use when saving the dataset.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>def save_xarray(\n    ds: xr.Dataset,\n    output_path: str | Path,\n    encoding_kwargs: dict[str, Any],\n) -&gt; None:\n    \"\"\"Save an xarray dataset to a file with standard parameters.\n\n    Parameters\n    ----------\n    ds\n        The dataset to save.\n    output_path\n        The path to save the dataset to.\n    encoding_kwargs\n        The encoding parameters to use when saving the dataset.\n    \"\"\"\n    touch(output_path, clobber=True)\n    encoding = {\n        \"dtype\": \"int16\",\n        \"_FillValue\": -32767,\n        \"zlib\": True,\n        \"complevel\": 1,\n    }\n    encoding.update(encoding_kwargs)\n    ds.to_netcdf(output_path, encoding={\"value\": encoding})\n</code></pre>"},{"location":"reference/climate_data/#climate_data.extract","title":"<code>extract</code>","text":""},{"location":"reference/climate_data/#climate_data.extract--climate-data-extraction","title":"Climate Data Extraction","text":"<p>This module contains pipelines for extracting climate data from various sources.</p>"},{"location":"reference/climate_data/#climate_data.extract.cmip6","title":"<code>cmip6</code>","text":""},{"location":"reference/climate_data/#climate_data.extract.cmip6--cmip6-data-extraction","title":"CMIP6 Data Extraction","text":""},{"location":"reference/climate_data/#climate_data.extract.cmip6.extract_cmip6","title":"<code>extract_cmip6(cmip6_source: list[str], cmip6_experiment: list[str], cmip6_variable: list[str], output_dir: str, queue: str, overwrite: bool) -&gt; None</code>","text":"<p>Extract CMIP6 data.</p> <p>Extracts CMIP6 data for the given source, experiment, and variable. We use the the table at https://www.nature.com/articles/s41597-023-02549-6/tables/3 to determine which CMIP6 source_ids to include. See <code>ClimateData.load_koppen_geiger_model_inclusion</code> to load and examine this table. The extraction criteria does not completely capture model inclusion criteria as it does not account for the year range avaialable in the data. This determiniation is made when we proccess the data in later steps.</p> Source code in <code>src/climate_data/extract/cmip6.py</code> <pre><code>@click.command()\n@clio.with_cmip6_source(allow_all=True)\n@clio.with_cmip6_experiment(allow_all=True)\n@clio.with_cmip6_variable(allow_all=True)\n@clio.with_output_directory(cdc.MODEL_ROOT)\n@clio.with_queue()\n@clio.with_overwrite()\ndef extract_cmip6(\n    cmip6_source: list[str],\n    cmip6_experiment: list[str],\n    cmip6_variable: list[str],\n    output_dir: str,\n    queue: str,\n    overwrite: bool,\n) -&gt; None:\n    \"\"\"Extract CMIP6 data.\n\n    Extracts CMIP6 data for the given source, experiment, and variable. We use the\n    the table at https://www.nature.com/articles/s41597-023-02549-6/tables/3 to determine\n    which CMIP6 source_ids to include. See `ClimateData.load_koppen_geiger_model_inclusion`\n    to load and examine this table. The extraction criteria does not completely\n    capture model inclusion criteria as it does not account for the year range avaialable\n    in the data. This determiniation is made when we proccess the data in later steps.\n    \"\"\"\n    overwrite_arg = {\"overwrite\": None} if overwrite else {}\n\n    jobmon.run_parallel(\n        runner=\"cdtask\",\n        task_name=\"extract cmip6\",\n        node_args={\n            \"cmip6-source\": cmip6_source,\n            \"cmip6-experiment\": cmip6_experiment,\n            \"cmip6-variable\": cmip6_variable,\n        },\n        task_args={\n            \"output-dir\": output_dir,\n            **overwrite_arg,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 1,\n            \"memory\": \"10G\",\n            \"runtime\": \"3000m\",\n            \"project\": \"proj_rapidresponse\",\n        },\n        max_attempts=1,\n        concurrency_limit=50,\n    )\n</code></pre>"},{"location":"reference/climate_data/#climate_data.extract.cmip6.load_cmip_data","title":"<code>load_cmip_data(zarr_path: str) -&gt; xr.Dataset</code>","text":"<p>Loads a CMIP6 dataset from a zarr path.</p> Source code in <code>src/climate_data/extract/cmip6.py</code> <pre><code>def load_cmip_data(zarr_path: str) -&gt; xr.Dataset:\n    \"\"\"Loads a CMIP6 dataset from a zarr path.\"\"\"\n    gcs = gcsfs.GCSFileSystem(token=\"anon\")  # noqa: S106\n    mapper = gcs.get_mapper(zarr_path)\n    ds = xr.open_zarr(mapper, consolidated=True)\n    ds = ds.drop_vars(\n        [\"lat_bnds\", \"lon_bnds\", \"time_bnds\", \"height\", \"time_bounds\", \"bnds\"],\n        errors=\"ignore\",\n    )\n    return ds  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/climate_data/#climate_data.extract.elevation","title":"<code>elevation</code>","text":""},{"location":"reference/climate_data/#climate_data.extract.elevation.extract_elevation","title":"<code>extract_elevation(model_name: str, output_dir: str, queue: str) -&gt; None</code>","text":"<p>Download elevation data from Open Topography.</p> Source code in <code>src/climate_data/extract/elevation.py</code> <pre><code>@click.command()\n@click.option(\n    \"--generate-name\",\n    required=True,\n    type=click.Choice(ELEVATION_MODELS),\n    help=\"Name of the elevation model to download.\",\n)\n@clio.with_output_directory(cdc.MODEL_ROOT)\n@clio.with_queue()\ndef extract_elevation(\n    model_name: str,\n    output_dir: str,\n    queue: str,\n) -&gt; None:\n    \"\"\"Download elevation data from Open Topography.\"\"\"\n    invalid = True\n    if invalid:\n        msg = \"Downloaded using aws cli, this implementation is not valid\"\n        raise NotImplementedError(msg)\n\n    lat_starts = list(range(-90, 90, FETCH_SIZE))\n    lon_starts = list(range(-180, 180, FETCH_SIZE))\n\n    jobmon.run_parallel(\n        runner=\"cdtask\",\n        task_name=\"extract elevation\",\n        node_args={\n            \"model-name\": [model_name],\n            \"lat-start\": lat_starts,\n            \"lon-start\": lon_starts,\n        },\n        task_args={\n            \"output-dir\": output_dir,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 1,\n            \"memory\": \"10G\",\n            \"runtime\": \"240m\",\n            \"project\": \"proj_rapidresponse\",\n        },\n    )\n</code></pre>"},{"location":"reference/climate_data/#climate_data.extract.elevation.extract_elevation_task","title":"<code>extract_elevation_task(model_name: str, lat_start: int, lon_start: int, output_dir: str) -&gt; None</code>","text":"<p>Download elevation data from Open Topography.</p> Source code in <code>src/climate_data/extract/elevation.py</code> <pre><code>@click.command()\n@click.option(\n    \"--model-name\",\n    required=True,\n    type=click.Choice(ELEVATION_MODELS),\n    help=\"Name of the elevation model to download.\",\n)\n@click.option(\n    \"--lat-start\",\n    required=True,\n    type=int,\n    help=\"Latitude of the top-left corner of the tile.\",\n)\n@click.option(\n    \"--lon-start\",\n    required=True,\n    type=int,\n    help=\"Longitude of the top-left corner of the tile.\",\n)\n@clio.with_output_directory(cdc.MODEL_ROOT)\ndef extract_elevation_task(\n    model_name: str,\n    lat_start: int,\n    lon_start: int,\n    output_dir: str,\n) -&gt; None:\n    \"\"\"Download elevation data from Open Topography.\"\"\"\n    invalid = True\n    if invalid:\n        msg = \"Downloaded using aws cli, this implementation is not valid\"\n        raise NotImplementedError(msg)\n\n    extract_elevation_main(model_name, lat_start, lon_start, output_dir)\n</code></pre>"},{"location":"reference/climate_data/#climate_data.extract.era5","title":"<code>era5</code>","text":""},{"location":"reference/climate_data/#climate_data.extract.era5--era5-data-extraction","title":"ERA5 Data Extraction","text":""},{"location":"reference/climate_data/#climate_data.generate","title":"<code>generate</code>","text":""},{"location":"reference/climate_data/#climate_data.generate.utils","title":"<code>utils</code>","text":""},{"location":"reference/climate_data/#climate_data.generate.utils.buck_vapor_pressure","title":"<code>buck_vapor_pressure(temperature_c: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Approximate vapor pressure of water.</p> <p>https://en.wikipedia.org/wiki/Arden_Buck_equation https://journals.ametsoc.org/view/journals/apme/20/12/1520-0450_1981_020_1527_nefcvp_2_0_co_2.xml</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.buck_vapor_pressure--parameters","title":"Parameters","text":"<p>temperature_c     Temperature in Celsius</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.buck_vapor_pressure--returns","title":"Returns","text":"<p>xr.Dataset     Vapor pressure in hPa</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def buck_vapor_pressure(temperature_c: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Approximate vapor pressure of water.\n\n    https://en.wikipedia.org/wiki/Arden_Buck_equation\n    https://journals.ametsoc.org/view/journals/apme/20/12/1520-0450_1981_020_1527_nefcvp_2_0_co_2.xml\n\n    Parameters\n    ----------\n    temperature_c\n        Temperature in Celsius\n\n    Returns\n    -------\n    xr.Dataset\n        Vapor pressure in hPa\n    \"\"\"\n    over_water = 6.1121 * np.exp(\n        (18.678 - temperature_c / 234.5) * (temperature_c / (257.14 + temperature_c))\n    )\n    over_ice = 6.1115 * np.exp(\n        (23.036 - temperature_c / 333.7) * (temperature_c / (279.82 + temperature_c))\n    )\n    vp = xr.where(temperature_c &gt; 0, over_water, over_ice)  # type: ignore[no-untyped-call]\n    return vp  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/climate_data/#climate_data.generate.utils.identity","title":"<code>identity(ds: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Identity transformation</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def identity(ds: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Identity transformation\"\"\"\n    return ds\n</code></pre>"},{"location":"reference/climate_data/#climate_data.generate.utils.interpolate_to_target_latlon","title":"<code>interpolate_to_target_latlon(ds: xr.Dataset, method: str = 'nearest', target_lon: xr.DataArray = cdc.TARGET_LONGITUDE, target_lat: xr.DataArray = cdc.TARGET_LATITUDE) -&gt; xr.Dataset</code>","text":"<p>Interpolate a dataset to a target latitude and longitude grid.</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.interpolate_to_target_latlon--parameters","title":"Parameters","text":"<p>ds     Dataset to interpolate method     Interpolation method target_lon     Target longitude grid target_lat     Target latitude grid</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.interpolate_to_target_latlon--returns","title":"Returns","text":"<p>xr.Dataset     Interpolated dataset</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def interpolate_to_target_latlon(\n    ds: xr.Dataset,\n    method: str = \"nearest\",\n    target_lon: xr.DataArray = cdc.TARGET_LONGITUDE,\n    target_lat: xr.DataArray = cdc.TARGET_LATITUDE,\n) -&gt; xr.Dataset:\n    \"\"\"Interpolate a dataset to a target latitude and longitude grid.\n\n    Parameters\n    ----------\n    ds\n        Dataset to interpolate\n    method\n        Interpolation method\n    target_lon\n        Target longitude grid\n    target_lat\n        Target latitude grid\n\n    Returns\n    -------\n    xr.Dataset\n        Interpolated dataset\n    \"\"\"\n    return (\n        ds.interp(longitude=target_lon, latitude=target_lat, method=method)  # type: ignore[arg-type]\n        .interpolate_na(dim=\"longitude\", method=\"nearest\", fill_value=\"extrapolate\")\n        .sortby(\"latitude\")\n        .interpolate_na(dim=\"latitude\", method=\"nearest\", fill_value=\"extrapolate\")\n        .sortby(\"latitude\", ascending=False)\n    )\n</code></pre>"},{"location":"reference/climate_data/#climate_data.generate.utils.kelvin_to_celsius","title":"<code>kelvin_to_celsius(temperature_k: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Convert temperature from Kelvin to Celsius</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.kelvin_to_celsius--parameters","title":"Parameters","text":"<p>temperature_k     Temperature in Kelvin</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.kelvin_to_celsius--returns","title":"Returns","text":"<p>xr.Dataset     Temperature in Celsius</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def kelvin_to_celsius(temperature_k: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Convert temperature from Kelvin to Celsius\n\n    Parameters\n    ----------\n    temperature_k\n        Temperature in Kelvin\n\n    Returns\n    -------\n    xr.Dataset\n        Temperature in Celsius\n    \"\"\"\n    return temperature_k - 273.15\n</code></pre>"},{"location":"reference/climate_data/#climate_data.generate.utils.meter_to_millimeter","title":"<code>meter_to_millimeter(rainfall_m: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Convert rainfall from meters to millimeters</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.meter_to_millimeter--parameters","title":"Parameters","text":"<p>rainfall_m     Rainfall in meters</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.meter_to_millimeter--returns","title":"Returns","text":"<p>xr.Dataset     Rainfall in millimeters</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def meter_to_millimeter(rainfall_m: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Convert rainfall from meters to millimeters\n\n    Parameters\n    ----------\n    rainfall_m\n        Rainfall in meters\n\n    Returns\n    -------\n    xr.Dataset\n        Rainfall in millimeters\n    \"\"\"\n    return 1000 * rainfall_m\n</code></pre>"},{"location":"reference/climate_data/#climate_data.generate.utils.precipitation_flux_to_rainfall","title":"<code>precipitation_flux_to_rainfall(precipitation_flux: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Convert precipitation flux to rainfall</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.precipitation_flux_to_rainfall--parameters","title":"Parameters","text":"<p>precipitation_flux     Precipitation flux in kg m-2 s-1</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.precipitation_flux_to_rainfall--returns","title":"Returns","text":"<p>xr.Dataset     Rainfall in mm/day</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def precipitation_flux_to_rainfall(precipitation_flux: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Convert precipitation flux to rainfall\n\n    Parameters\n    ----------\n    precipitation_flux\n        Precipitation flux in kg m-2 s-1\n\n    Returns\n    -------\n    xr.Dataset\n        Rainfall in mm/day\n    \"\"\"\n    seconds_per_day = 86400\n    mm_per_kg_m2 = 1\n    return seconds_per_day * mm_per_kg_m2 * precipitation_flux\n</code></pre>"},{"location":"reference/climate_data/#climate_data.generate.utils.rh_percent","title":"<code>rh_percent(temperature_c: xr.Dataset, dewpoint_temperature_c: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Calculate relative humidity from temperature and dewpoint temperature.</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.rh_percent--parameters","title":"Parameters","text":"<p>temperature_c     Temperature in Celsius dewpoint_temperature_c     Dewpoint temperature in Celsius</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.rh_percent--returns","title":"Returns","text":"<p>xr.Dataset     Relative humidity as a percentage</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def rh_percent(\n    temperature_c: xr.Dataset, dewpoint_temperature_c: xr.Dataset\n) -&gt; xr.Dataset:\n    \"\"\"Calculate relative humidity from temperature and dewpoint temperature.\n\n    Parameters\n    ----------\n    temperature_c\n        Temperature in Celsius\n    dewpoint_temperature_c\n        Dewpoint temperature in Celsius\n\n    Returns\n    -------\n    xr.Dataset\n        Relative humidity as a percentage\n    \"\"\"\n    # saturation vapour pressure\n    svp = buck_vapor_pressure(temperature_c)\n    # actual vapour pressure\n    vp = buck_vapor_pressure(dewpoint_temperature_c)\n    return 100 * vp / svp\n</code></pre>"},{"location":"reference/climate_data/#climate_data.generate.utils.scale_wind_speed_height","title":"<code>scale_wind_speed_height(wind_speed_10m: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Scaling wind speed from a height of 10 meters to a height of 2 meters</p> <p>Reference: Br\u00f6de et al. (2012) https://doi.org/10.1007/s00484-011-0454-1</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.scale_wind_speed_height--parameters","title":"Parameters","text":"<p>wind_speed_10m     The 10m wind speed [m/s]. May be signed (ie a velocity component)</p>"},{"location":"reference/climate_data/#climate_data.generate.utils.scale_wind_speed_height--returns","title":"Returns","text":"<p>xr.DataSet     The 2m wind speed [m/s]. May be signed (ie a velocity component)</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def scale_wind_speed_height(wind_speed_10m: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Scaling wind speed from a height of 10 meters to a height of 2 meters\n\n    Reference: Br\u00f6de et al. (2012)\n    https://doi.org/10.1007/s00484-011-0454-1\n\n    Parameters\n    ----------\n    wind_speed_10m\n        The 10m wind speed [m/s]. May be signed (ie a velocity component)\n\n    Returns\n    -------\n    xr.DataSet\n        The 2m wind speed [m/s]. May be signed (ie a velocity component)\n    \"\"\"\n    scale_factor = np.log10(2 / 0.01) / np.log10(10 / 0.01)\n    return scale_factor * wind_speed_10m  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/climate_data/#climate_data.generate.utils.vector_magnitude","title":"<code>vector_magnitude(x: xr.Dataset, y: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Calculate the magnitude of a vector.</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def vector_magnitude(x: xr.Dataset, y: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Calculate the magnitude of a vector.\"\"\"\n    return np.sqrt(x**2 + y**2)  # type: ignore[return-value]\n</code></pre>"},{"location":"reference/climate_data/#climate_data.utils","title":"<code>utils</code>","text":""},{"location":"reference/climate_data/#climate_data.utils--climate-data-utilities","title":"Climate Data Utilities","text":"<p>Utility functions for working with climate data.</p>"},{"location":"reference/climate_data/#climate_data.utils.make_raster_template","title":"<code>make_raster_template(x_min: int | float, y_min: int | float, stride: int | float, resolution: int | float, crs: str = 'EPSG:4326') -&gt; rt.RasterArray</code>","text":"<p>Create a raster template with the specified dimensions and resolution.</p> <p>A raster template is a RasterArray with a specified extent, resolution, and CRS. The data values are initialized to zero. This function is useful for creating a template to use when resampling another raster to a common grid.</p>"},{"location":"reference/climate_data/#climate_data.utils.make_raster_template--parameters","title":"Parameters","text":"<p>x_min     The minimum x-coordinate of the raster. y_min     The minimum y-coordinate of the raster. stride     The length of one side of the raster in the x and y directions measured in the units     of the provided coordinate reference system. resolution     The resolution of the raster in the units of the provided coordinate reference system. crs     The coordinate reference system of the generated raster.</p>"},{"location":"reference/climate_data/#climate_data.utils.make_raster_template--returns","title":"Returns","text":"<p>rt.RasterArray     A raster template with the specified dimensions and resolution.</p> Source code in <code>src/climate_data/utils.py</code> <pre><code>def make_raster_template(\n    x_min: int | float,\n    y_min: int | float,\n    stride: int | float,\n    resolution: int | float,\n    crs: str = \"EPSG:4326\",\n) -&gt; rt.RasterArray:\n    \"\"\"Create a raster template with the specified dimensions and resolution.\n\n    A raster template is a RasterArray with a specified extent, resolution, and CRS. The data\n    values are initialized to zero. This function is useful for creating a template to use\n    when resampling another raster to a common grid.\n\n    Parameters\n    ----------\n    x_min\n        The minimum x-coordinate of the raster.\n    y_min\n        The minimum y-coordinate of the raster.\n    stride\n        The length of one side of the raster in the x and y directions measured in the units\n        of the provided coordinate reference system.\n    resolution\n        The resolution of the raster in the units of the provided coordinate reference system.\n    crs\n        The coordinate reference system of the generated raster.\n\n    Returns\n    -------\n    rt.RasterArray\n        A raster template with the specified dimensions and resolution.\n    \"\"\"\n    tolerance = 1e-12\n    evenly_divides = (stride % resolution &lt; tolerance) or (\n        resolution - stride % resolution &lt; tolerance\n    )\n    if not evenly_divides:\n        msg = \"Stride must be a multiple of resolution\"\n        raise ValueError(msg)\n\n    transform = Affine(\n        a=resolution,\n        b=0,\n        c=x_min,\n        d=0,\n        e=-resolution,\n        f=y_min + stride,\n    )\n\n    n_pix = int(stride / resolution)\n\n    data = np.zeros((n_pix, n_pix), dtype=np.int8)\n    return rt.RasterArray(\n        data,\n        transform,\n        crs=crs,\n        no_data_value=-1,\n    )\n</code></pre>"},{"location":"reference/climate_data/#climate_data.utils.to_raster","title":"<code>to_raster(ds: xr.DataArray, no_data_value: float | int, lat_col: str = 'lat', lon_col: str = 'lon', crs: str = 'EPSG:4326') -&gt; rt.RasterArray</code>","text":"<p>Convert an xarray DataArray to a RasterArray.</p>"},{"location":"reference/climate_data/#climate_data.utils.to_raster--parameters","title":"Parameters","text":"<p>ds     The xarray DataArray to convert. no_data_value     The value to use for missing data. This should be consistent with the dtype of the data. lat_col     The name of the latitude coordinate in the dataset. lon_col     The name of the longitude coordinate in the dataset. crs     The coordinate reference system of the data.</p>"},{"location":"reference/climate_data/#climate_data.utils.to_raster--returns","title":"Returns","text":"<p>rt.RasterArray     The RasterArray representation of the input data.</p> Source code in <code>src/climate_data/utils.py</code> <pre><code>def to_raster(\n    ds: xr.DataArray,\n    no_data_value: float | int,\n    lat_col: str = \"lat\",\n    lon_col: str = \"lon\",\n    crs: str = \"EPSG:4326\",\n) -&gt; rt.RasterArray:\n    \"\"\"Convert an xarray DataArray to a RasterArray.\n\n    Parameters\n    ----------\n    ds\n        The xarray DataArray to convert.\n    no_data_value\n        The value to use for missing data. This should be consistent with the dtype of the data.\n    lat_col\n        The name of the latitude coordinate in the dataset.\n    lon_col\n        The name of the longitude coordinate in the dataset.\n    crs\n        The coordinate reference system of the data.\n\n    Returns\n    -------\n    rt.RasterArray\n        The RasterArray representation of the input data.\n    \"\"\"\n    lat, lon = ds[lat_col].data, ds[lon_col].data\n\n    dlat = (lat[1:] - lat[:-1]).mean()\n    dlon = (lon[1:] - lon[:-1]).mean()\n\n    transform = Affine(\n        a=dlon,\n        b=0.0,\n        c=lon[0],\n        d=0.0,\n        e=-dlat,\n        f=lat[-1],\n    )\n    return rt.RasterArray(\n        data=ds.data[::-1],\n        transform=transform,\n        crs=crs,\n        no_data_value=no_data_value,\n    )\n</code></pre>"},{"location":"reference/climate_data/cli/","title":"cli","text":""},{"location":"reference/climate_data/cli/#climate_data.cli.cdrun","title":"<code>cdrun() -&gt; None</code>","text":"<p>Entry point for running climate downscale workflows.</p> Source code in <code>src/climate_data/cli.py</code> <pre><code>@click.group()\ndef cdrun() -&gt; None:\n    \"\"\"Entry point for running climate downscale workflows.\"\"\"\n</code></pre>"},{"location":"reference/climate_data/cli/#climate_data.cli.cdtask","title":"<code>cdtask() -&gt; None</code>","text":"<p>Entry point for running climate downscale tasks.</p> Source code in <code>src/climate_data/cli.py</code> <pre><code>@click.group()\ndef cdtask() -&gt; None:\n    \"\"\"Entry point for running climate downscale tasks.\"\"\"\n</code></pre>"},{"location":"reference/climate_data/cli_options/","title":"cli_options","text":""},{"location":"reference/climate_data/cli_options/#climate_data.cli_options--climate-data-cli-options","title":"Climate Data CLI Options","text":"<p>This module provides a set of CLI options for extracting climate data from the ERA5 and CMIP6 datasets. These options are used to specify the data to extract, such as the year, month, variable, and dataset. It also provides global variables representing the full space of valid values for these options.</p>"},{"location":"reference/climate_data/cli_options/#climate_data.cli_options.with_year","title":"<code>with_year(years: Collection[str], *, allow_all: bool = False) -&gt; Callable[[Callable[P, T]], Callable[P, T]]</code>","text":"<p>Create a CLI option for selecting a year.</p> Source code in <code>src/climate_data/cli_options.py</code> <pre><code>def with_year[**P, T](\n    years: Collection[str],\n    *,\n    allow_all: bool = False,\n) -&gt; Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Create a CLI option for selecting a year.\"\"\"\n    return with_choice(\n        \"year\",\n        \"y\",\n        allow_all=allow_all,\n        choices=years,\n        help=\"Year to extract data for.\",\n        convert=allow_all,\n    )\n</code></pre>"},{"location":"reference/climate_data/constants/","title":"constants","text":""},{"location":"reference/climate_data/data/","title":"data","text":""},{"location":"reference/climate_data/data/#climate_data.data--climate-data-management","title":"Climate Data Management","text":"<p>This module provides a class for managing the climate data used in the project. It includes methods for loading and saving data, as well as for accessing the various directories where data is stored. This abstraction allows for easy access to the data and ensures that all data is stored in a consistent and organized manner. It also provides a central location for managing the data, which makes it easier to update and maintain the path structure of the data as needed.</p> <p>This module generally does not load or process data itself, though some exceptions are made for metadata which is generally loaded and cached on disk.</p>"},{"location":"reference/climate_data/data/#climate_data.data.ClimateData","title":"<code>ClimateData</code>","text":"<p>Class for managing the climate data used in the project.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>class ClimateData:\n    \"\"\"Class for managing the climate data used in the project.\"\"\"\n\n    def __init__(\n        self, root: str | Path = cdc.MODEL_ROOT, *, create_root: bool = True\n    ) -&gt; None:\n        self._root = Path(root)\n        self._credentials_root = self._root / \"credentials\"\n        if create_root:\n            self._create_model_root()\n\n    def _create_model_root(self) -&gt; None:\n        mkdir(self.root, exist_ok=True)\n        mkdir(self.credentials_root, exist_ok=True)\n\n        mkdir(self.extracted_data, exist_ok=True)\n        mkdir(self.extracted_era5, exist_ok=True)\n        mkdir(self.extracted_cmip6, exist_ok=True)\n        mkdir(self.ncei_climate_stations, exist_ok=True)\n        mkdir(self.open_topography_elevation, exist_ok=True)\n        mkdir(self.rub_local_climate_zones, exist_ok=True)\n\n        mkdir(self.downscale_model, exist_ok=True)\n        mkdir(self.predictors, exist_ok=True)\n        mkdir(self.training_data, exist_ok=True)\n\n        mkdir(self.results, exist_ok=True)\n        mkdir(self.results_metadata, exist_ok=True)\n        mkdir(self.daily_results, exist_ok=True)\n        mkdir(self.raw_daily_results, exist_ok=True)\n        mkdir(self.annual_results, exist_ok=True)\n        mkdir(self.raw_annual_results, exist_ok=True)\n\n    @property\n    def root(self) -&gt; Path:\n        return self._root\n\n    @property\n    def credentials_root(self) -&gt; Path:\n        return self._credentials_root\n\n    ##################\n    # Extracted data #\n    ##################\n\n    @property\n    def extracted_data(self) -&gt; Path:\n        return self.root / \"extracted_data\"\n\n    @property\n    def extracted_era5(self) -&gt; Path:\n        return self.extracted_data / \"era5\"\n\n    def extracted_era5_path(\n        self, dataset: str, variable: str, year: int | str, month: str\n    ) -&gt; Path:\n        return self.extracted_era5 / f\"{dataset}_{variable}_{year}_{month}.nc\"\n\n    @property\n    def extracted_cmip6(self) -&gt; Path:\n        return self.extracted_data / \"cmip6\"\n\n    def load_koppen_geiger_model_inclusion(\n        self, *, return_full_criteria: bool = False\n    ) -&gt; pd.DataFrame:\n        meta_path = self.extracted_cmip6 / \"koppen_geiger_model_inclusion.parquet\"\n\n        if not meta_path.exists():\n            df = pd.read_html(\n                \"https://www.nature.com/articles/s41597-023-02549-6/tables/3\"\n            )[0]\n            df.columns = [  # type: ignore[assignment]\n                \"source_id\",\n                \"member_count\",\n                \"mean_trend\",\n                \"std_dev_trend\",\n                \"transient_climate_response\",\n                \"equilibrium_climate_sensitivity\",\n                \"included_raw\",\n            ]\n            df[\"included\"] = df[\"included_raw\"].apply({\"Yes\": True, \"No\": False}.get)\n            save_parquet(df, meta_path)\n\n        df = pd.read_parquet(meta_path)\n        if return_full_criteria:\n            return df\n        return df[[\"source_id\", \"included\"]]\n\n    def load_cmip6_metadata(self) -&gt; pd.DataFrame:\n        meta_path = self.extracted_cmip6 / \"cmip6-metadata.parquet\"\n\n        if not meta_path.exists():\n            external_path = \"https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv\"\n            meta = pd.read_csv(external_path)\n            save_parquet(meta, meta_path)\n\n        return pd.read_parquet(meta_path)\n\n    def extracted_cmip6_path(\n        self,\n        variable: str,\n        experiment: str,\n        gcm_member: str,\n    ) -&gt; Path:\n        return self.extracted_cmip6 / f\"{variable}_{experiment}_{gcm_member}.nc\"\n\n    def get_gcms(\n        self,\n        source_variables: Collection[str],\n    ) -&gt; list[str]:\n        inclusion_meta = self.load_scenario_inclusion_metadata()[source_variables]\n        inclusion_meta = inclusion_meta[inclusion_meta.all(axis=1)]\n        return [\n            f\"{model}_{variant}\" for model, variant in inclusion_meta.index.tolist()\n        ]\n\n    @property\n    def ncei_climate_stations(self) -&gt; Path:\n        return self.extracted_data / \"ncei_climate_stations\"\n\n    def save_ncei_climate_stations(self, df: pd.DataFrame, year: int | str) -&gt; None:\n        path = self.ncei_climate_stations / f\"{year}.parquet\"\n        save_parquet(df, path)\n\n    def load_ncei_climate_stations(self, year: int | str) -&gt; pd.DataFrame:\n        return pd.read_parquet(self.ncei_climate_stations / f\"{year}.parquet\")\n\n    @property\n    def open_topography_elevation(self) -&gt; Path:\n        return self.extracted_data / \"open_topography_elevation\"\n\n    @property\n    def rub_local_climate_zones(self) -&gt; Path:\n        return self.extracted_data / \"rub_local_climate_zones\"\n\n    ###################\n    # Downscale model #\n    ###################\n\n    @property\n    def downscale_model(self) -&gt; Path:\n        return self.root / \"downscale_model\"\n\n    @property\n    def predictors(self) -&gt; Path:\n        return self.downscale_model / \"predictors\"\n\n    def save_predictor(\n        self,\n        predictor: rt.RasterArray,\n        name: str,\n        lat_start: int,\n        lon_start: int,\n    ) -&gt; None:\n        path = self.predictors / f\"{name}_{lat_start}_{lon_start}.tif\"\n        save_raster(predictor, path)\n\n    def load_predictor(self, name: str) -&gt; rt.RasterArray:\n        paths = list(self.predictors.glob(f\"{name}_*.tif\"))\n        return rt.load_mf_raster(paths)\n\n    @property\n    def training_data(self) -&gt; Path:\n        return self.downscale_model / \"training_data\"\n\n    def save_training_data(self, df: pd.DataFrame, year: int | str) -&gt; None:\n        path = self.training_data / f\"{year}.parquet\"\n        save_parquet(df, path)\n\n    def load_training_data(self, year: int | str) -&gt; pd.DataFrame:\n        return pd.read_parquet(self.training_data / f\"{year}.parquet\")\n\n    ###########\n    # Results #\n    ###########\n\n    @property\n    def results(self) -&gt; Path:\n        return self.root / \"results\"\n\n    @property\n    def results_metadata(self) -&gt; Path:\n        return self.results / \"metadata\"\n\n    def save_scenario_metadata(self, df: pd.DataFrame) -&gt; None:\n        path = self.results_metadata / \"scenario_metadata.parquet\"\n        save_parquet(df, path)\n\n    def load_scenario_metadata(self) -&gt; pd.DataFrame:\n        path = self.results_metadata / \"scenario_metadata.parquet\"\n        return pd.read_parquet(path)\n\n    def save_scenario_inclusion_metadata(self, df: pd.DataFrame) -&gt; None:\n        # Need to save to our scripts directory for doc building\n        scripts_root = Path(__file__).parent.parent.parent / \"scripts\"\n        for root_dir in [self.results_metadata, scripts_root]:\n            path = root_dir / \"scenario_inclusion_metadata.parquet\"\n            save_parquet(df, path)\n\n    def load_scenario_inclusion_metadata(self) -&gt; pd.DataFrame:\n        path = self.results_metadata / \"scenario_inclusion_metadata.parquet\"\n        return pd.read_parquet(path)\n\n    @property\n    def daily_results(self) -&gt; Path:\n        return self.results / \"daily\"\n\n    @property\n    def raw_daily_results(self) -&gt; Path:\n        return self.daily_results / \"raw\"\n\n    def raw_daily_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        gcm_member: str,\n    ) -&gt; Path:\n        return self.raw_daily_results / scenario / variable / f\"{year}_{gcm_member}.nc\"\n\n    def save_raw_daily_results(\n        self,\n        results_ds: xr.Dataset,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        gcm_member: str,\n        encoding_kwargs: dict[str, Any],\n    ) -&gt; None:\n        path = self.raw_daily_results_path(scenario, variable, year, gcm_member)\n        mkdir(path.parent, exist_ok=True, parents=True)\n        save_xarray(results_ds, path, encoding_kwargs)\n\n    def daily_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        year: int | str,\n    ) -&gt; Path:\n        return self.daily_results / scenario / variable / f\"{year}.nc\"\n\n    def save_daily_results(\n        self,\n        results_ds: xr.Dataset,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        encoding_kwargs: dict[str, Any],\n    ) -&gt; None:\n        path = self.daily_results_path(scenario, variable, year)\n        mkdir(path.parent, exist_ok=True, parents=True)\n        save_xarray(results_ds, path, encoding_kwargs)\n\n    def load_daily_results(\n        self,\n        scenario: str,\n        variable: str,\n        year: int | str,\n    ) -&gt; xr.Dataset:\n        results_path = self.daily_results_path(scenario, variable, year)\n        return xr.open_dataset(results_path)\n\n    @property\n    def annual_results(self) -&gt; Path:\n        return self.results / \"annual\"\n\n    @property\n    def raw_annual_results(self) -&gt; Path:\n        return self.annual_results / \"raw\"\n\n    def raw_annual_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        gcm_member: str,\n    ) -&gt; Path:\n        return self.raw_annual_results / scenario / variable / f\"{year}_{gcm_member}.nc\"\n\n    def save_raw_annual_results(\n        self,\n        results_ds: xr.Dataset,\n        scenario: str,\n        variable: str,\n        year: int | str,\n        gcm_member: str,\n        encoding_kwargs: dict[str, Any],\n    ) -&gt; None:\n        path = self.raw_annual_results_path(scenario, variable, year, gcm_member)\n        mkdir(path.parent, exist_ok=True, parents=True)\n        save_xarray(results_ds, path, encoding_kwargs)\n\n    @property\n    def compiled_annual_results(self) -&gt; Path:\n        return self.raw_annual_results / \"compiled\"\n\n    def compiled_annual_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        gcm_member: str,\n    ) -&gt; Path:\n        return self.compiled_annual_results / scenario / variable / f\"{gcm_member}.nc\"\n\n    def save_compiled_annual_results(\n        self,\n        results_ds: xr.Dataset,\n        scenario: str,\n        variable: str,\n        gcm_member: str,\n    ) -&gt; None:\n        path = self.compiled_annual_results_path(scenario, variable, gcm_member)\n        mkdir(path.parent, exist_ok=True, parents=True)\n        touch(path, clobber=True)\n        results_ds.to_netcdf(path)\n\n    def annual_results_path(\n        self,\n        scenario: str,\n        variable: str,\n        draw: int | str,\n    ) -&gt; Path:\n        return self.annual_results / scenario / variable / f\"{draw:0&gt;3}.nc\"\n\n    def link_annual_draw(\n        self,\n        draw: int | str,\n        scenario: str,\n        variable: str,\n        gcm_member: str,\n    ) -&gt; None:\n        source_path = self.compiled_annual_results_path(scenario, variable, gcm_member)\n        dest_path = self.annual_results_path(scenario, variable, draw)\n        mkdir(dest_path.parent, exist_ok=True, parents=True)\n        if dest_path.exists():\n            dest_path.unlink()\n        dest_path.symlink_to(source_path)\n</code></pre>"},{"location":"reference/climate_data/data/#climate_data.data.save_parquet","title":"<code>save_parquet(df: pd.DataFrame, output_path: str | Path) -&gt; None</code>","text":"<p>Save a pandas DataFrame to a file with standard parameters.</p>"},{"location":"reference/climate_data/data/#climate_data.data.save_parquet--parameters","title":"Parameters","text":"<p>df     The DataFrame to save. output_path     The path to save the DataFrame to.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>def save_parquet(\n    df: pd.DataFrame,\n    output_path: str | Path,\n) -&gt; None:\n    \"\"\"Save a pandas DataFrame to a file with standard parameters.\n\n    Parameters\n    ----------\n    df\n        The DataFrame to save.\n    output_path\n        The path to save the DataFrame to.\n    \"\"\"\n    touch(output_path, clobber=True)\n    df.to_parquet(output_path)\n</code></pre>"},{"location":"reference/climate_data/data/#climate_data.data.save_raster","title":"<code>save_raster(raster: rt.RasterArray, output_path: str | Path, num_cores: int = 1, **kwargs: Any) -&gt; None</code>","text":"<p>Save a raster to a file with standard parameters.</p>"},{"location":"reference/climate_data/data/#climate_data.data.save_raster--parameters","title":"Parameters","text":"<p>raster     The raster to save. output_path     The path to save the raster to. num_cores     The number of cores to use for compression.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>def save_raster(\n    raster: rt.RasterArray,\n    output_path: str | Path,\n    num_cores: int = 1,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Save a raster to a file with standard parameters.\n\n    Parameters\n    ----------\n    raster\n        The raster to save.\n    output_path\n        The path to save the raster to.\n    num_cores\n        The number of cores to use for compression.\n    \"\"\"\n    save_params = {\n        \"tiled\": True,\n        \"blockxsize\": 512,\n        \"blockysize\": 512,\n        \"compress\": \"ZSTD\",\n        \"predictor\": 2,  # horizontal differencing\n        \"num_threads\": num_cores,\n        \"bigtiff\": \"yes\",\n        **kwargs,\n    }\n    touch(output_path, clobber=True)\n    raster.to_file(output_path, **save_params)\n</code></pre>"},{"location":"reference/climate_data/data/#climate_data.data.save_raster_to_cog","title":"<code>save_raster_to_cog(raster: rt.RasterArray, output_path: str | Path, num_cores: int = 1, resampling: str = 'nearest') -&gt; None</code>","text":"<p>Save a raster to a COG file.</p> <p>A COG file is a cloud-optimized GeoTIFF that is optimized for use in cloud storage systems. This function saves the raster to a COG file with the specified resampling method.</p>"},{"location":"reference/climate_data/data/#climate_data.data.save_raster_to_cog--parameters","title":"Parameters","text":"<p>raster     The raster to save. output_path     The path to save the raster to. num_cores     The number of cores to use for compression. resampling     The resampling method to use when building the overviews.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>def save_raster_to_cog(\n    raster: rt.RasterArray,\n    output_path: str | Path,\n    num_cores: int = 1,\n    resampling: str = \"nearest\",\n) -&gt; None:\n    \"\"\"Save a raster to a COG file.\n\n    A COG file is a cloud-optimized GeoTIFF that is optimized for use in cloud storage\n    systems. This function saves the raster to a COG file with the specified resampling\n    method.\n\n    Parameters\n    ----------\n    raster\n        The raster to save.\n    output_path\n        The path to save the raster to.\n    num_cores\n        The number of cores to use for compression.\n    resampling\n        The resampling method to use when building the overviews.\n    \"\"\"\n    cog_save_params = {\n        \"driver\": \"COG\",\n        \"overview_resampling\": resampling,\n    }\n    save_raster(raster, output_path, num_cores, **cog_save_params)\n</code></pre>"},{"location":"reference/climate_data/data/#climate_data.data.save_xarray","title":"<code>save_xarray(ds: xr.Dataset, output_path: str | Path, encoding_kwargs: dict[str, Any]) -&gt; None</code>","text":"<p>Save an xarray dataset to a file with standard parameters.</p>"},{"location":"reference/climate_data/data/#climate_data.data.save_xarray--parameters","title":"Parameters","text":"<p>ds     The dataset to save. output_path     The path to save the dataset to. encoding_kwargs     The encoding parameters to use when saving the dataset.</p> Source code in <code>src/climate_data/data.py</code> <pre><code>def save_xarray(\n    ds: xr.Dataset,\n    output_path: str | Path,\n    encoding_kwargs: dict[str, Any],\n) -&gt; None:\n    \"\"\"Save an xarray dataset to a file with standard parameters.\n\n    Parameters\n    ----------\n    ds\n        The dataset to save.\n    output_path\n        The path to save the dataset to.\n    encoding_kwargs\n        The encoding parameters to use when saving the dataset.\n    \"\"\"\n    touch(output_path, clobber=True)\n    encoding = {\n        \"dtype\": \"int16\",\n        \"_FillValue\": -32767,\n        \"zlib\": True,\n        \"complevel\": 1,\n    }\n    encoding.update(encoding_kwargs)\n    ds.to_netcdf(output_path, encoding={\"value\": encoding})\n</code></pre>"},{"location":"reference/climate_data/utils/","title":"utils","text":""},{"location":"reference/climate_data/utils/#climate_data.utils--climate-data-utilities","title":"Climate Data Utilities","text":"<p>Utility functions for working with climate data.</p>"},{"location":"reference/climate_data/utils/#climate_data.utils.make_raster_template","title":"<code>make_raster_template(x_min: int | float, y_min: int | float, stride: int | float, resolution: int | float, crs: str = 'EPSG:4326') -&gt; rt.RasterArray</code>","text":"<p>Create a raster template with the specified dimensions and resolution.</p> <p>A raster template is a RasterArray with a specified extent, resolution, and CRS. The data values are initialized to zero. This function is useful for creating a template to use when resampling another raster to a common grid.</p>"},{"location":"reference/climate_data/utils/#climate_data.utils.make_raster_template--parameters","title":"Parameters","text":"<p>x_min     The minimum x-coordinate of the raster. y_min     The minimum y-coordinate of the raster. stride     The length of one side of the raster in the x and y directions measured in the units     of the provided coordinate reference system. resolution     The resolution of the raster in the units of the provided coordinate reference system. crs     The coordinate reference system of the generated raster.</p>"},{"location":"reference/climate_data/utils/#climate_data.utils.make_raster_template--returns","title":"Returns","text":"<p>rt.RasterArray     A raster template with the specified dimensions and resolution.</p> Source code in <code>src/climate_data/utils.py</code> <pre><code>def make_raster_template(\n    x_min: int | float,\n    y_min: int | float,\n    stride: int | float,\n    resolution: int | float,\n    crs: str = \"EPSG:4326\",\n) -&gt; rt.RasterArray:\n    \"\"\"Create a raster template with the specified dimensions and resolution.\n\n    A raster template is a RasterArray with a specified extent, resolution, and CRS. The data\n    values are initialized to zero. This function is useful for creating a template to use\n    when resampling another raster to a common grid.\n\n    Parameters\n    ----------\n    x_min\n        The minimum x-coordinate of the raster.\n    y_min\n        The minimum y-coordinate of the raster.\n    stride\n        The length of one side of the raster in the x and y directions measured in the units\n        of the provided coordinate reference system.\n    resolution\n        The resolution of the raster in the units of the provided coordinate reference system.\n    crs\n        The coordinate reference system of the generated raster.\n\n    Returns\n    -------\n    rt.RasterArray\n        A raster template with the specified dimensions and resolution.\n    \"\"\"\n    tolerance = 1e-12\n    evenly_divides = (stride % resolution &lt; tolerance) or (\n        resolution - stride % resolution &lt; tolerance\n    )\n    if not evenly_divides:\n        msg = \"Stride must be a multiple of resolution\"\n        raise ValueError(msg)\n\n    transform = Affine(\n        a=resolution,\n        b=0,\n        c=x_min,\n        d=0,\n        e=-resolution,\n        f=y_min + stride,\n    )\n\n    n_pix = int(stride / resolution)\n\n    data = np.zeros((n_pix, n_pix), dtype=np.int8)\n    return rt.RasterArray(\n        data,\n        transform,\n        crs=crs,\n        no_data_value=-1,\n    )\n</code></pre>"},{"location":"reference/climate_data/utils/#climate_data.utils.to_raster","title":"<code>to_raster(ds: xr.DataArray, no_data_value: float | int, lat_col: str = 'lat', lon_col: str = 'lon', crs: str = 'EPSG:4326') -&gt; rt.RasterArray</code>","text":"<p>Convert an xarray DataArray to a RasterArray.</p>"},{"location":"reference/climate_data/utils/#climate_data.utils.to_raster--parameters","title":"Parameters","text":"<p>ds     The xarray DataArray to convert. no_data_value     The value to use for missing data. This should be consistent with the dtype of the data. lat_col     The name of the latitude coordinate in the dataset. lon_col     The name of the longitude coordinate in the dataset. crs     The coordinate reference system of the data.</p>"},{"location":"reference/climate_data/utils/#climate_data.utils.to_raster--returns","title":"Returns","text":"<p>rt.RasterArray     The RasterArray representation of the input data.</p> Source code in <code>src/climate_data/utils.py</code> <pre><code>def to_raster(\n    ds: xr.DataArray,\n    no_data_value: float | int,\n    lat_col: str = \"lat\",\n    lon_col: str = \"lon\",\n    crs: str = \"EPSG:4326\",\n) -&gt; rt.RasterArray:\n    \"\"\"Convert an xarray DataArray to a RasterArray.\n\n    Parameters\n    ----------\n    ds\n        The xarray DataArray to convert.\n    no_data_value\n        The value to use for missing data. This should be consistent with the dtype of the data.\n    lat_col\n        The name of the latitude coordinate in the dataset.\n    lon_col\n        The name of the longitude coordinate in the dataset.\n    crs\n        The coordinate reference system of the data.\n\n    Returns\n    -------\n    rt.RasterArray\n        The RasterArray representation of the input data.\n    \"\"\"\n    lat, lon = ds[lat_col].data, ds[lon_col].data\n\n    dlat = (lat[1:] - lat[:-1]).mean()\n    dlon = (lon[1:] - lon[:-1]).mean()\n\n    transform = Affine(\n        a=dlon,\n        b=0.0,\n        c=lon[0],\n        d=0.0,\n        e=-dlat,\n        f=lat[-1],\n    )\n    return rt.RasterArray(\n        data=ds.data[::-1],\n        transform=transform,\n        crs=crs,\n        no_data_value=no_data_value,\n    )\n</code></pre>"},{"location":"reference/climate_data/downscale/","title":"downscale","text":""},{"location":"reference/climate_data/downscale/prepare_predictors/","title":"prepare_predictors","text":""},{"location":"reference/climate_data/downscale/prepare_training_data/","title":"prepare_training_data","text":""},{"location":"reference/climate_data/extract/","title":"extract","text":""},{"location":"reference/climate_data/extract/#climate_data.extract--climate-data-extraction","title":"Climate Data Extraction","text":"<p>This module contains pipelines for extracting climate data from various sources.</p>"},{"location":"reference/climate_data/extract/#climate_data.extract.cmip6","title":"<code>cmip6</code>","text":""},{"location":"reference/climate_data/extract/#climate_data.extract.cmip6--cmip6-data-extraction","title":"CMIP6 Data Extraction","text":""},{"location":"reference/climate_data/extract/#climate_data.extract.cmip6.extract_cmip6","title":"<code>extract_cmip6(cmip6_source: list[str], cmip6_experiment: list[str], cmip6_variable: list[str], output_dir: str, queue: str, overwrite: bool) -&gt; None</code>","text":"<p>Extract CMIP6 data.</p> <p>Extracts CMIP6 data for the given source, experiment, and variable. We use the the table at https://www.nature.com/articles/s41597-023-02549-6/tables/3 to determine which CMIP6 source_ids to include. See <code>ClimateData.load_koppen_geiger_model_inclusion</code> to load and examine this table. The extraction criteria does not completely capture model inclusion criteria as it does not account for the year range avaialable in the data. This determiniation is made when we proccess the data in later steps.</p> Source code in <code>src/climate_data/extract/cmip6.py</code> <pre><code>@click.command()\n@clio.with_cmip6_source(allow_all=True)\n@clio.with_cmip6_experiment(allow_all=True)\n@clio.with_cmip6_variable(allow_all=True)\n@clio.with_output_directory(cdc.MODEL_ROOT)\n@clio.with_queue()\n@clio.with_overwrite()\ndef extract_cmip6(\n    cmip6_source: list[str],\n    cmip6_experiment: list[str],\n    cmip6_variable: list[str],\n    output_dir: str,\n    queue: str,\n    overwrite: bool,\n) -&gt; None:\n    \"\"\"Extract CMIP6 data.\n\n    Extracts CMIP6 data for the given source, experiment, and variable. We use the\n    the table at https://www.nature.com/articles/s41597-023-02549-6/tables/3 to determine\n    which CMIP6 source_ids to include. See `ClimateData.load_koppen_geiger_model_inclusion`\n    to load and examine this table. The extraction criteria does not completely\n    capture model inclusion criteria as it does not account for the year range avaialable\n    in the data. This determiniation is made when we proccess the data in later steps.\n    \"\"\"\n    overwrite_arg = {\"overwrite\": None} if overwrite else {}\n\n    jobmon.run_parallel(\n        runner=\"cdtask\",\n        task_name=\"extract cmip6\",\n        node_args={\n            \"cmip6-source\": cmip6_source,\n            \"cmip6-experiment\": cmip6_experiment,\n            \"cmip6-variable\": cmip6_variable,\n        },\n        task_args={\n            \"output-dir\": output_dir,\n            **overwrite_arg,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 1,\n            \"memory\": \"10G\",\n            \"runtime\": \"3000m\",\n            \"project\": \"proj_rapidresponse\",\n        },\n        max_attempts=1,\n        concurrency_limit=50,\n    )\n</code></pre>"},{"location":"reference/climate_data/extract/#climate_data.extract.cmip6.load_cmip_data","title":"<code>load_cmip_data(zarr_path: str) -&gt; xr.Dataset</code>","text":"<p>Loads a CMIP6 dataset from a zarr path.</p> Source code in <code>src/climate_data/extract/cmip6.py</code> <pre><code>def load_cmip_data(zarr_path: str) -&gt; xr.Dataset:\n    \"\"\"Loads a CMIP6 dataset from a zarr path.\"\"\"\n    gcs = gcsfs.GCSFileSystem(token=\"anon\")  # noqa: S106\n    mapper = gcs.get_mapper(zarr_path)\n    ds = xr.open_zarr(mapper, consolidated=True)\n    ds = ds.drop_vars(\n        [\"lat_bnds\", \"lon_bnds\", \"time_bnds\", \"height\", \"time_bounds\", \"bnds\"],\n        errors=\"ignore\",\n    )\n    return ds  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/climate_data/extract/#climate_data.extract.elevation","title":"<code>elevation</code>","text":""},{"location":"reference/climate_data/extract/#climate_data.extract.elevation.extract_elevation","title":"<code>extract_elevation(model_name: str, output_dir: str, queue: str) -&gt; None</code>","text":"<p>Download elevation data from Open Topography.</p> Source code in <code>src/climate_data/extract/elevation.py</code> <pre><code>@click.command()\n@click.option(\n    \"--generate-name\",\n    required=True,\n    type=click.Choice(ELEVATION_MODELS),\n    help=\"Name of the elevation model to download.\",\n)\n@clio.with_output_directory(cdc.MODEL_ROOT)\n@clio.with_queue()\ndef extract_elevation(\n    model_name: str,\n    output_dir: str,\n    queue: str,\n) -&gt; None:\n    \"\"\"Download elevation data from Open Topography.\"\"\"\n    invalid = True\n    if invalid:\n        msg = \"Downloaded using aws cli, this implementation is not valid\"\n        raise NotImplementedError(msg)\n\n    lat_starts = list(range(-90, 90, FETCH_SIZE))\n    lon_starts = list(range(-180, 180, FETCH_SIZE))\n\n    jobmon.run_parallel(\n        runner=\"cdtask\",\n        task_name=\"extract elevation\",\n        node_args={\n            \"model-name\": [model_name],\n            \"lat-start\": lat_starts,\n            \"lon-start\": lon_starts,\n        },\n        task_args={\n            \"output-dir\": output_dir,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 1,\n            \"memory\": \"10G\",\n            \"runtime\": \"240m\",\n            \"project\": \"proj_rapidresponse\",\n        },\n    )\n</code></pre>"},{"location":"reference/climate_data/extract/#climate_data.extract.elevation.extract_elevation_task","title":"<code>extract_elevation_task(model_name: str, lat_start: int, lon_start: int, output_dir: str) -&gt; None</code>","text":"<p>Download elevation data from Open Topography.</p> Source code in <code>src/climate_data/extract/elevation.py</code> <pre><code>@click.command()\n@click.option(\n    \"--model-name\",\n    required=True,\n    type=click.Choice(ELEVATION_MODELS),\n    help=\"Name of the elevation model to download.\",\n)\n@click.option(\n    \"--lat-start\",\n    required=True,\n    type=int,\n    help=\"Latitude of the top-left corner of the tile.\",\n)\n@click.option(\n    \"--lon-start\",\n    required=True,\n    type=int,\n    help=\"Longitude of the top-left corner of the tile.\",\n)\n@clio.with_output_directory(cdc.MODEL_ROOT)\ndef extract_elevation_task(\n    model_name: str,\n    lat_start: int,\n    lon_start: int,\n    output_dir: str,\n) -&gt; None:\n    \"\"\"Download elevation data from Open Topography.\"\"\"\n    invalid = True\n    if invalid:\n        msg = \"Downloaded using aws cli, this implementation is not valid\"\n        raise NotImplementedError(msg)\n\n    extract_elevation_main(model_name, lat_start, lon_start, output_dir)\n</code></pre>"},{"location":"reference/climate_data/extract/#climate_data.extract.era5","title":"<code>era5</code>","text":""},{"location":"reference/climate_data/extract/#climate_data.extract.era5--era5-data-extraction","title":"ERA5 Data Extraction","text":""},{"location":"reference/climate_data/extract/cmip6/","title":"cmip6","text":""},{"location":"reference/climate_data/extract/cmip6/#climate_data.extract.cmip6--cmip6-data-extraction","title":"CMIP6 Data Extraction","text":""},{"location":"reference/climate_data/extract/cmip6/#climate_data.extract.cmip6.extract_cmip6","title":"<code>extract_cmip6(cmip6_source: list[str], cmip6_experiment: list[str], cmip6_variable: list[str], output_dir: str, queue: str, overwrite: bool) -&gt; None</code>","text":"<p>Extract CMIP6 data.</p> <p>Extracts CMIP6 data for the given source, experiment, and variable. We use the the table at https://www.nature.com/articles/s41597-023-02549-6/tables/3 to determine which CMIP6 source_ids to include. See <code>ClimateData.load_koppen_geiger_model_inclusion</code> to load and examine this table. The extraction criteria does not completely capture model inclusion criteria as it does not account for the year range avaialable in the data. This determiniation is made when we proccess the data in later steps.</p> Source code in <code>src/climate_data/extract/cmip6.py</code> <pre><code>@click.command()\n@clio.with_cmip6_source(allow_all=True)\n@clio.with_cmip6_experiment(allow_all=True)\n@clio.with_cmip6_variable(allow_all=True)\n@clio.with_output_directory(cdc.MODEL_ROOT)\n@clio.with_queue()\n@clio.with_overwrite()\ndef extract_cmip6(\n    cmip6_source: list[str],\n    cmip6_experiment: list[str],\n    cmip6_variable: list[str],\n    output_dir: str,\n    queue: str,\n    overwrite: bool,\n) -&gt; None:\n    \"\"\"Extract CMIP6 data.\n\n    Extracts CMIP6 data for the given source, experiment, and variable. We use the\n    the table at https://www.nature.com/articles/s41597-023-02549-6/tables/3 to determine\n    which CMIP6 source_ids to include. See `ClimateData.load_koppen_geiger_model_inclusion`\n    to load and examine this table. The extraction criteria does not completely\n    capture model inclusion criteria as it does not account for the year range avaialable\n    in the data. This determiniation is made when we proccess the data in later steps.\n    \"\"\"\n    overwrite_arg = {\"overwrite\": None} if overwrite else {}\n\n    jobmon.run_parallel(\n        runner=\"cdtask\",\n        task_name=\"extract cmip6\",\n        node_args={\n            \"cmip6-source\": cmip6_source,\n            \"cmip6-experiment\": cmip6_experiment,\n            \"cmip6-variable\": cmip6_variable,\n        },\n        task_args={\n            \"output-dir\": output_dir,\n            **overwrite_arg,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 1,\n            \"memory\": \"10G\",\n            \"runtime\": \"3000m\",\n            \"project\": \"proj_rapidresponse\",\n        },\n        max_attempts=1,\n        concurrency_limit=50,\n    )\n</code></pre>"},{"location":"reference/climate_data/extract/cmip6/#climate_data.extract.cmip6.load_cmip_data","title":"<code>load_cmip_data(zarr_path: str) -&gt; xr.Dataset</code>","text":"<p>Loads a CMIP6 dataset from a zarr path.</p> Source code in <code>src/climate_data/extract/cmip6.py</code> <pre><code>def load_cmip_data(zarr_path: str) -&gt; xr.Dataset:\n    \"\"\"Loads a CMIP6 dataset from a zarr path.\"\"\"\n    gcs = gcsfs.GCSFileSystem(token=\"anon\")  # noqa: S106\n    mapper = gcs.get_mapper(zarr_path)\n    ds = xr.open_zarr(mapper, consolidated=True)\n    ds = ds.drop_vars(\n        [\"lat_bnds\", \"lon_bnds\", \"time_bnds\", \"height\", \"time_bounds\", \"bnds\"],\n        errors=\"ignore\",\n    )\n    return ds  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/climate_data/extract/elevation/","title":"elevation","text":""},{"location":"reference/climate_data/extract/elevation/#climate_data.extract.elevation.extract_elevation","title":"<code>extract_elevation(model_name: str, output_dir: str, queue: str) -&gt; None</code>","text":"<p>Download elevation data from Open Topography.</p> Source code in <code>src/climate_data/extract/elevation.py</code> <pre><code>@click.command()\n@click.option(\n    \"--generate-name\",\n    required=True,\n    type=click.Choice(ELEVATION_MODELS),\n    help=\"Name of the elevation model to download.\",\n)\n@clio.with_output_directory(cdc.MODEL_ROOT)\n@clio.with_queue()\ndef extract_elevation(\n    model_name: str,\n    output_dir: str,\n    queue: str,\n) -&gt; None:\n    \"\"\"Download elevation data from Open Topography.\"\"\"\n    invalid = True\n    if invalid:\n        msg = \"Downloaded using aws cli, this implementation is not valid\"\n        raise NotImplementedError(msg)\n\n    lat_starts = list(range(-90, 90, FETCH_SIZE))\n    lon_starts = list(range(-180, 180, FETCH_SIZE))\n\n    jobmon.run_parallel(\n        runner=\"cdtask\",\n        task_name=\"extract elevation\",\n        node_args={\n            \"model-name\": [model_name],\n            \"lat-start\": lat_starts,\n            \"lon-start\": lon_starts,\n        },\n        task_args={\n            \"output-dir\": output_dir,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 1,\n            \"memory\": \"10G\",\n            \"runtime\": \"240m\",\n            \"project\": \"proj_rapidresponse\",\n        },\n    )\n</code></pre>"},{"location":"reference/climate_data/extract/elevation/#climate_data.extract.elevation.extract_elevation_task","title":"<code>extract_elevation_task(model_name: str, lat_start: int, lon_start: int, output_dir: str) -&gt; None</code>","text":"<p>Download elevation data from Open Topography.</p> Source code in <code>src/climate_data/extract/elevation.py</code> <pre><code>@click.command()\n@click.option(\n    \"--model-name\",\n    required=True,\n    type=click.Choice(ELEVATION_MODELS),\n    help=\"Name of the elevation model to download.\",\n)\n@click.option(\n    \"--lat-start\",\n    required=True,\n    type=int,\n    help=\"Latitude of the top-left corner of the tile.\",\n)\n@click.option(\n    \"--lon-start\",\n    required=True,\n    type=int,\n    help=\"Longitude of the top-left corner of the tile.\",\n)\n@clio.with_output_directory(cdc.MODEL_ROOT)\ndef extract_elevation_task(\n    model_name: str,\n    lat_start: int,\n    lon_start: int,\n    output_dir: str,\n) -&gt; None:\n    \"\"\"Download elevation data from Open Topography.\"\"\"\n    invalid = True\n    if invalid:\n        msg = \"Downloaded using aws cli, this implementation is not valid\"\n        raise NotImplementedError(msg)\n\n    extract_elevation_main(model_name, lat_start, lon_start, output_dir)\n</code></pre>"},{"location":"reference/climate_data/extract/era5/","title":"era5","text":""},{"location":"reference/climate_data/extract/era5/#climate_data.extract.era5--era5-data-extraction","title":"ERA5 Data Extraction","text":""},{"location":"reference/climate_data/extract/ncei_climate_stations/","title":"ncei_climate_stations","text":""},{"location":"reference/climate_data/extract/rub_local_climate_zones/","title":"rub_local_climate_zones","text":""},{"location":"reference/climate_data/generate/","title":"generate","text":""},{"location":"reference/climate_data/generate/#climate_data.generate.utils","title":"<code>utils</code>","text":""},{"location":"reference/climate_data/generate/#climate_data.generate.utils.buck_vapor_pressure","title":"<code>buck_vapor_pressure(temperature_c: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Approximate vapor pressure of water.</p> <p>https://en.wikipedia.org/wiki/Arden_Buck_equation https://journals.ametsoc.org/view/journals/apme/20/12/1520-0450_1981_020_1527_nefcvp_2_0_co_2.xml</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.buck_vapor_pressure--parameters","title":"Parameters","text":"<p>temperature_c     Temperature in Celsius</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.buck_vapor_pressure--returns","title":"Returns","text":"<p>xr.Dataset     Vapor pressure in hPa</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def buck_vapor_pressure(temperature_c: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Approximate vapor pressure of water.\n\n    https://en.wikipedia.org/wiki/Arden_Buck_equation\n    https://journals.ametsoc.org/view/journals/apme/20/12/1520-0450_1981_020_1527_nefcvp_2_0_co_2.xml\n\n    Parameters\n    ----------\n    temperature_c\n        Temperature in Celsius\n\n    Returns\n    -------\n    xr.Dataset\n        Vapor pressure in hPa\n    \"\"\"\n    over_water = 6.1121 * np.exp(\n        (18.678 - temperature_c / 234.5) * (temperature_c / (257.14 + temperature_c))\n    )\n    over_ice = 6.1115 * np.exp(\n        (23.036 - temperature_c / 333.7) * (temperature_c / (279.82 + temperature_c))\n    )\n    vp = xr.where(temperature_c &gt; 0, over_water, over_ice)  # type: ignore[no-untyped-call]\n    return vp  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.identity","title":"<code>identity(ds: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Identity transformation</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def identity(ds: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Identity transformation\"\"\"\n    return ds\n</code></pre>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.interpolate_to_target_latlon","title":"<code>interpolate_to_target_latlon(ds: xr.Dataset, method: str = 'nearest', target_lon: xr.DataArray = cdc.TARGET_LONGITUDE, target_lat: xr.DataArray = cdc.TARGET_LATITUDE) -&gt; xr.Dataset</code>","text":"<p>Interpolate a dataset to a target latitude and longitude grid.</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.interpolate_to_target_latlon--parameters","title":"Parameters","text":"<p>ds     Dataset to interpolate method     Interpolation method target_lon     Target longitude grid target_lat     Target latitude grid</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.interpolate_to_target_latlon--returns","title":"Returns","text":"<p>xr.Dataset     Interpolated dataset</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def interpolate_to_target_latlon(\n    ds: xr.Dataset,\n    method: str = \"nearest\",\n    target_lon: xr.DataArray = cdc.TARGET_LONGITUDE,\n    target_lat: xr.DataArray = cdc.TARGET_LATITUDE,\n) -&gt; xr.Dataset:\n    \"\"\"Interpolate a dataset to a target latitude and longitude grid.\n\n    Parameters\n    ----------\n    ds\n        Dataset to interpolate\n    method\n        Interpolation method\n    target_lon\n        Target longitude grid\n    target_lat\n        Target latitude grid\n\n    Returns\n    -------\n    xr.Dataset\n        Interpolated dataset\n    \"\"\"\n    return (\n        ds.interp(longitude=target_lon, latitude=target_lat, method=method)  # type: ignore[arg-type]\n        .interpolate_na(dim=\"longitude\", method=\"nearest\", fill_value=\"extrapolate\")\n        .sortby(\"latitude\")\n        .interpolate_na(dim=\"latitude\", method=\"nearest\", fill_value=\"extrapolate\")\n        .sortby(\"latitude\", ascending=False)\n    )\n</code></pre>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.kelvin_to_celsius","title":"<code>kelvin_to_celsius(temperature_k: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Convert temperature from Kelvin to Celsius</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.kelvin_to_celsius--parameters","title":"Parameters","text":"<p>temperature_k     Temperature in Kelvin</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.kelvin_to_celsius--returns","title":"Returns","text":"<p>xr.Dataset     Temperature in Celsius</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def kelvin_to_celsius(temperature_k: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Convert temperature from Kelvin to Celsius\n\n    Parameters\n    ----------\n    temperature_k\n        Temperature in Kelvin\n\n    Returns\n    -------\n    xr.Dataset\n        Temperature in Celsius\n    \"\"\"\n    return temperature_k - 273.15\n</code></pre>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.meter_to_millimeter","title":"<code>meter_to_millimeter(rainfall_m: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Convert rainfall from meters to millimeters</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.meter_to_millimeter--parameters","title":"Parameters","text":"<p>rainfall_m     Rainfall in meters</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.meter_to_millimeter--returns","title":"Returns","text":"<p>xr.Dataset     Rainfall in millimeters</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def meter_to_millimeter(rainfall_m: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Convert rainfall from meters to millimeters\n\n    Parameters\n    ----------\n    rainfall_m\n        Rainfall in meters\n\n    Returns\n    -------\n    xr.Dataset\n        Rainfall in millimeters\n    \"\"\"\n    return 1000 * rainfall_m\n</code></pre>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.precipitation_flux_to_rainfall","title":"<code>precipitation_flux_to_rainfall(precipitation_flux: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Convert precipitation flux to rainfall</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.precipitation_flux_to_rainfall--parameters","title":"Parameters","text":"<p>precipitation_flux     Precipitation flux in kg m-2 s-1</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.precipitation_flux_to_rainfall--returns","title":"Returns","text":"<p>xr.Dataset     Rainfall in mm/day</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def precipitation_flux_to_rainfall(precipitation_flux: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Convert precipitation flux to rainfall\n\n    Parameters\n    ----------\n    precipitation_flux\n        Precipitation flux in kg m-2 s-1\n\n    Returns\n    -------\n    xr.Dataset\n        Rainfall in mm/day\n    \"\"\"\n    seconds_per_day = 86400\n    mm_per_kg_m2 = 1\n    return seconds_per_day * mm_per_kg_m2 * precipitation_flux\n</code></pre>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.rh_percent","title":"<code>rh_percent(temperature_c: xr.Dataset, dewpoint_temperature_c: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Calculate relative humidity from temperature and dewpoint temperature.</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.rh_percent--parameters","title":"Parameters","text":"<p>temperature_c     Temperature in Celsius dewpoint_temperature_c     Dewpoint temperature in Celsius</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.rh_percent--returns","title":"Returns","text":"<p>xr.Dataset     Relative humidity as a percentage</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def rh_percent(\n    temperature_c: xr.Dataset, dewpoint_temperature_c: xr.Dataset\n) -&gt; xr.Dataset:\n    \"\"\"Calculate relative humidity from temperature and dewpoint temperature.\n\n    Parameters\n    ----------\n    temperature_c\n        Temperature in Celsius\n    dewpoint_temperature_c\n        Dewpoint temperature in Celsius\n\n    Returns\n    -------\n    xr.Dataset\n        Relative humidity as a percentage\n    \"\"\"\n    # saturation vapour pressure\n    svp = buck_vapor_pressure(temperature_c)\n    # actual vapour pressure\n    vp = buck_vapor_pressure(dewpoint_temperature_c)\n    return 100 * vp / svp\n</code></pre>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.scale_wind_speed_height","title":"<code>scale_wind_speed_height(wind_speed_10m: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Scaling wind speed from a height of 10 meters to a height of 2 meters</p> <p>Reference: Br\u00f6de et al. (2012) https://doi.org/10.1007/s00484-011-0454-1</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.scale_wind_speed_height--parameters","title":"Parameters","text":"<p>wind_speed_10m     The 10m wind speed [m/s]. May be signed (ie a velocity component)</p>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.scale_wind_speed_height--returns","title":"Returns","text":"<p>xr.DataSet     The 2m wind speed [m/s]. May be signed (ie a velocity component)</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def scale_wind_speed_height(wind_speed_10m: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Scaling wind speed from a height of 10 meters to a height of 2 meters\n\n    Reference: Br\u00f6de et al. (2012)\n    https://doi.org/10.1007/s00484-011-0454-1\n\n    Parameters\n    ----------\n    wind_speed_10m\n        The 10m wind speed [m/s]. May be signed (ie a velocity component)\n\n    Returns\n    -------\n    xr.DataSet\n        The 2m wind speed [m/s]. May be signed (ie a velocity component)\n    \"\"\"\n    scale_factor = np.log10(2 / 0.01) / np.log10(10 / 0.01)\n    return scale_factor * wind_speed_10m  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/climate_data/generate/#climate_data.generate.utils.vector_magnitude","title":"<code>vector_magnitude(x: xr.Dataset, y: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Calculate the magnitude of a vector.</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def vector_magnitude(x: xr.Dataset, y: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Calculate the magnitude of a vector.\"\"\"\n    return np.sqrt(x**2 + y**2)  # type: ignore[return-value]\n</code></pre>"},{"location":"reference/climate_data/generate/draws/","title":"draws","text":""},{"location":"reference/climate_data/generate/historical_daily/","title":"historical_daily","text":""},{"location":"reference/climate_data/generate/historical_reference/","title":"historical_reference","text":""},{"location":"reference/climate_data/generate/scenario_annual/","title":"scenario_annual","text":""},{"location":"reference/climate_data/generate/scenario_daily/","title":"scenario_daily","text":""},{"location":"reference/climate_data/generate/scenario_inclusion/","title":"scenario_inclusion","text":""},{"location":"reference/climate_data/generate/temperature_zones/","title":"temperature_zones","text":""},{"location":"reference/climate_data/generate/utils/","title":"utils","text":""},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.buck_vapor_pressure","title":"<code>buck_vapor_pressure(temperature_c: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Approximate vapor pressure of water.</p> <p>https://en.wikipedia.org/wiki/Arden_Buck_equation https://journals.ametsoc.org/view/journals/apme/20/12/1520-0450_1981_020_1527_nefcvp_2_0_co_2.xml</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.buck_vapor_pressure--parameters","title":"Parameters","text":"<p>temperature_c     Temperature in Celsius</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.buck_vapor_pressure--returns","title":"Returns","text":"<p>xr.Dataset     Vapor pressure in hPa</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def buck_vapor_pressure(temperature_c: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Approximate vapor pressure of water.\n\n    https://en.wikipedia.org/wiki/Arden_Buck_equation\n    https://journals.ametsoc.org/view/journals/apme/20/12/1520-0450_1981_020_1527_nefcvp_2_0_co_2.xml\n\n    Parameters\n    ----------\n    temperature_c\n        Temperature in Celsius\n\n    Returns\n    -------\n    xr.Dataset\n        Vapor pressure in hPa\n    \"\"\"\n    over_water = 6.1121 * np.exp(\n        (18.678 - temperature_c / 234.5) * (temperature_c / (257.14 + temperature_c))\n    )\n    over_ice = 6.1115 * np.exp(\n        (23.036 - temperature_c / 333.7) * (temperature_c / (279.82 + temperature_c))\n    )\n    vp = xr.where(temperature_c &gt; 0, over_water, over_ice)  # type: ignore[no-untyped-call]\n    return vp  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.identity","title":"<code>identity(ds: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Identity transformation</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def identity(ds: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Identity transformation\"\"\"\n    return ds\n</code></pre>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.interpolate_to_target_latlon","title":"<code>interpolate_to_target_latlon(ds: xr.Dataset, method: str = 'nearest', target_lon: xr.DataArray = cdc.TARGET_LONGITUDE, target_lat: xr.DataArray = cdc.TARGET_LATITUDE) -&gt; xr.Dataset</code>","text":"<p>Interpolate a dataset to a target latitude and longitude grid.</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.interpolate_to_target_latlon--parameters","title":"Parameters","text":"<p>ds     Dataset to interpolate method     Interpolation method target_lon     Target longitude grid target_lat     Target latitude grid</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.interpolate_to_target_latlon--returns","title":"Returns","text":"<p>xr.Dataset     Interpolated dataset</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def interpolate_to_target_latlon(\n    ds: xr.Dataset,\n    method: str = \"nearest\",\n    target_lon: xr.DataArray = cdc.TARGET_LONGITUDE,\n    target_lat: xr.DataArray = cdc.TARGET_LATITUDE,\n) -&gt; xr.Dataset:\n    \"\"\"Interpolate a dataset to a target latitude and longitude grid.\n\n    Parameters\n    ----------\n    ds\n        Dataset to interpolate\n    method\n        Interpolation method\n    target_lon\n        Target longitude grid\n    target_lat\n        Target latitude grid\n\n    Returns\n    -------\n    xr.Dataset\n        Interpolated dataset\n    \"\"\"\n    return (\n        ds.interp(longitude=target_lon, latitude=target_lat, method=method)  # type: ignore[arg-type]\n        .interpolate_na(dim=\"longitude\", method=\"nearest\", fill_value=\"extrapolate\")\n        .sortby(\"latitude\")\n        .interpolate_na(dim=\"latitude\", method=\"nearest\", fill_value=\"extrapolate\")\n        .sortby(\"latitude\", ascending=False)\n    )\n</code></pre>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.kelvin_to_celsius","title":"<code>kelvin_to_celsius(temperature_k: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Convert temperature from Kelvin to Celsius</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.kelvin_to_celsius--parameters","title":"Parameters","text":"<p>temperature_k     Temperature in Kelvin</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.kelvin_to_celsius--returns","title":"Returns","text":"<p>xr.Dataset     Temperature in Celsius</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def kelvin_to_celsius(temperature_k: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Convert temperature from Kelvin to Celsius\n\n    Parameters\n    ----------\n    temperature_k\n        Temperature in Kelvin\n\n    Returns\n    -------\n    xr.Dataset\n        Temperature in Celsius\n    \"\"\"\n    return temperature_k - 273.15\n</code></pre>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.meter_to_millimeter","title":"<code>meter_to_millimeter(rainfall_m: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Convert rainfall from meters to millimeters</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.meter_to_millimeter--parameters","title":"Parameters","text":"<p>rainfall_m     Rainfall in meters</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.meter_to_millimeter--returns","title":"Returns","text":"<p>xr.Dataset     Rainfall in millimeters</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def meter_to_millimeter(rainfall_m: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Convert rainfall from meters to millimeters\n\n    Parameters\n    ----------\n    rainfall_m\n        Rainfall in meters\n\n    Returns\n    -------\n    xr.Dataset\n        Rainfall in millimeters\n    \"\"\"\n    return 1000 * rainfall_m\n</code></pre>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.precipitation_flux_to_rainfall","title":"<code>precipitation_flux_to_rainfall(precipitation_flux: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Convert precipitation flux to rainfall</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.precipitation_flux_to_rainfall--parameters","title":"Parameters","text":"<p>precipitation_flux     Precipitation flux in kg m-2 s-1</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.precipitation_flux_to_rainfall--returns","title":"Returns","text":"<p>xr.Dataset     Rainfall in mm/day</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def precipitation_flux_to_rainfall(precipitation_flux: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Convert precipitation flux to rainfall\n\n    Parameters\n    ----------\n    precipitation_flux\n        Precipitation flux in kg m-2 s-1\n\n    Returns\n    -------\n    xr.Dataset\n        Rainfall in mm/day\n    \"\"\"\n    seconds_per_day = 86400\n    mm_per_kg_m2 = 1\n    return seconds_per_day * mm_per_kg_m2 * precipitation_flux\n</code></pre>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.rh_percent","title":"<code>rh_percent(temperature_c: xr.Dataset, dewpoint_temperature_c: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Calculate relative humidity from temperature and dewpoint temperature.</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.rh_percent--parameters","title":"Parameters","text":"<p>temperature_c     Temperature in Celsius dewpoint_temperature_c     Dewpoint temperature in Celsius</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.rh_percent--returns","title":"Returns","text":"<p>xr.Dataset     Relative humidity as a percentage</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def rh_percent(\n    temperature_c: xr.Dataset, dewpoint_temperature_c: xr.Dataset\n) -&gt; xr.Dataset:\n    \"\"\"Calculate relative humidity from temperature and dewpoint temperature.\n\n    Parameters\n    ----------\n    temperature_c\n        Temperature in Celsius\n    dewpoint_temperature_c\n        Dewpoint temperature in Celsius\n\n    Returns\n    -------\n    xr.Dataset\n        Relative humidity as a percentage\n    \"\"\"\n    # saturation vapour pressure\n    svp = buck_vapor_pressure(temperature_c)\n    # actual vapour pressure\n    vp = buck_vapor_pressure(dewpoint_temperature_c)\n    return 100 * vp / svp\n</code></pre>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.scale_wind_speed_height","title":"<code>scale_wind_speed_height(wind_speed_10m: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Scaling wind speed from a height of 10 meters to a height of 2 meters</p> <p>Reference: Br\u00f6de et al. (2012) https://doi.org/10.1007/s00484-011-0454-1</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.scale_wind_speed_height--parameters","title":"Parameters","text":"<p>wind_speed_10m     The 10m wind speed [m/s]. May be signed (ie a velocity component)</p>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.scale_wind_speed_height--returns","title":"Returns","text":"<p>xr.DataSet     The 2m wind speed [m/s]. May be signed (ie a velocity component)</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def scale_wind_speed_height(wind_speed_10m: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Scaling wind speed from a height of 10 meters to a height of 2 meters\n\n    Reference: Br\u00f6de et al. (2012)\n    https://doi.org/10.1007/s00484-011-0454-1\n\n    Parameters\n    ----------\n    wind_speed_10m\n        The 10m wind speed [m/s]. May be signed (ie a velocity component)\n\n    Returns\n    -------\n    xr.DataSet\n        The 2m wind speed [m/s]. May be signed (ie a velocity component)\n    \"\"\"\n    scale_factor = np.log10(2 / 0.01) / np.log10(10 / 0.01)\n    return scale_factor * wind_speed_10m  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/climate_data/generate/utils/#climate_data.generate.utils.vector_magnitude","title":"<code>vector_magnitude(x: xr.Dataset, y: xr.Dataset) -&gt; xr.Dataset</code>","text":"<p>Calculate the magnitude of a vector.</p> Source code in <code>src/climate_data/generate/utils.py</code> <pre><code>def vector_magnitude(x: xr.Dataset, y: xr.Dataset) -&gt; xr.Dataset:\n    \"\"\"Calculate the magnitude of a vector.\"\"\"\n    return np.sqrt(x**2 + y**2)  # type: ignore[return-value]\n</code></pre>"}]}